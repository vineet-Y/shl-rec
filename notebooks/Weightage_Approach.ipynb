{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c81a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4433fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "from hashlib import sha1\n",
    "from typing import List, Dict, Set, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af226c",
   "metadata": {},
   "source": [
    "Loading Dataset And Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a34123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_url</th>\n",
       "      <th>pdf_text</th>\n",
       "      <th>job_level</th>\n",
       "      <th>test_type</th>\n",
       "      <th>test_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Skills Development Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>This report is designed to be given to individ...</td>\n",
       "      <td>[Director, Entry-Level, Executive, General Pop...</td>\n",
       "      <td>[Ability &amp; Aptitude, Biodata &amp; Situational Jud...</td>\n",
       "      <td>[English (USA)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.NET Framework 4.5</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>The.NET Framework 4.5 test measures knowledge ...</td>\n",
       "      <td>[Mid-Professional, Professional Individual Con...</td>\n",
       "      <td>[Knowledge &amp; Skills]</td>\n",
       "      <td>[English (USA)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.NET MVC (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>Multi-choice test that measures the knowledge ...</td>\n",
       "      <td>[Mid-Professional, Professional Individual Con...</td>\n",
       "      <td>[Knowledge &amp; Skills]</td>\n",
       "      <td>[English (USA)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    assessment_name  \\\n",
       "0  Global Skills Development Report   \n",
       "1                .NET Framework 4.5   \n",
       "2                    .NET MVC (New)   \n",
       "\n",
       "                                      assessment_url  \\\n",
       "0  https://www.shl.com/products/product-catalog/v...   \n",
       "1  https://www.shl.com/products/product-catalog/v...   \n",
       "2  https://www.shl.com/products/product-catalog/v...   \n",
       "\n",
       "                                            pdf_text  \\\n",
       "0  This report is designed to be given to individ...   \n",
       "1  The.NET Framework 4.5 test measures knowledge ...   \n",
       "2  Multi-choice test that measures the knowledge ...   \n",
       "\n",
       "                                           job_level  \\\n",
       "0  [Director, Entry-Level, Executive, General Pop...   \n",
       "1  [Mid-Professional, Professional Individual Con...   \n",
       "2  [Mid-Professional, Professional Individual Con...   \n",
       "\n",
       "                                           test_type    test_language  \n",
       "0  [Ability & Aptitude, Biodata & Situational Jud...  [English (USA)]  \n",
       "1                               [Knowledge & Skills]  [English (USA)]  \n",
       "2                               [Knowledge & Skills]  [English (USA)]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"NewSHLDataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bb214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pdf_text\"] = df[\"pdf_text\"].astype(str).str.replace(r\"\\n\", \" \", regex=True)\n",
    "df[\"pdf_text\"] = (df[\"pdf_text\"].fillna(\"\").astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip())\n",
    "df[\"assessment_name\"] = df[\"assessment_name\"].fillna(\"\").astype(str).str.strip()\n",
    "df[\"assessment_url\"] = df[\"assessment_url\"].fillna(\"\").astype(str).str.strip()\n",
    "# Drop empty rows (optional)\n",
    "df = df[df[\"pdf_text\"].str.len() > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb8081",
   "metadata": {},
   "source": [
    "Changing the format of JD or Query to a structured one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5cae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PATHS ====\n",
    "DATA_CSV   = \"assessments_catalog.csv\"  \n",
    "CACHE_DIR  = Path(\"./embedding_cache\")  \n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== MODEL ====\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# ==== COLUMNS ====\n",
    "COL_PDF   = \"pdf_text\"\n",
    "COL_LEVEL = \"job_level\"\n",
    "COL_LANG  = \"test_language\"\n",
    "COL_NAME  = \"assessment_name\"\n",
    "COL_URL   = \"assessment_url\"\n",
    "\n",
    "# ==== RANKING WEIGHTS ====\n",
    "W_LOOK  = 0.65\n",
    "W_CONS  = 0.15\n",
    "W_LANG  = 0.10\n",
    "W_LEVEL = 0.10\n",
    "\n",
    "# ==== COVERAGE ====\n",
    "TOP_N = 10          # number of results to show\n",
    "GUARANTEE_TOP = 4   # ensure facet coverage within top-4\n",
    "K_PER_FACET = 3     # if coverage missing, pull from top-3 of that facet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9980cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000) # Increases the overall display width\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b75ab51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a stable integer id aligned to current file ordering\n",
    "df = df.reset_index(drop=False).rename(columns={\"index\": \"row_id\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c0ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== COLUMN CONSTANTS ====\n",
    "COL_PDF   = \"pdf_text\"\n",
    "COL_LEVEL = \"job_level\"\n",
    "COL_LANG  = \"test_language\"\n",
    "COL_NAME  = \"assessment_name\"\n",
    "COL_URL   = \"assessment_url\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156ca229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_text(x) -> str:\n",
    "    \"\"\"Normalize any text or list/dict/object into a clean string.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = \" \".join(map(str, x))\n",
    "    elif isinstance(x, dict):\n",
    "        x = json.dumps(x, ensure_ascii=False)\n",
    "    elif x is None:\n",
    "        x = \"\"\n",
    "    else:\n",
    "        x = str(x)\n",
    "    x = x.strip()\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    return x\n",
    "\n",
    "def _to_str_scalar(x) -> str:\n",
    "    if isinstance(x, list):\n",
    "        return \" \".join(map(str, x))\n",
    "    if isinstance(x, dict):\n",
    "        return json.dumps(x, ensure_ascii=False)\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    return str(x)\n",
    "\n",
    "def sanitize_rows_df(df_rows: pd.DataFrame, text_cols: list[str]) -> pd.DataFrame:\n",
    "    df_rows = df_rows.copy()\n",
    "    for c in text_cols:\n",
    "        if c in df_rows.columns:\n",
    "            df_rows[c] = df_rows[c].map(_to_str_scalar)\n",
    "            df_rows[c] = df_rows[c].astype(object)  # avoid pandas ExtensionDtypes\n",
    "    if \"row_id\" in df_rows.columns:\n",
    "        df_rows[\"row_id\"] = df_rows[\"row_id\"].astype(int)\n",
    "    return df_rows\n",
    "\n",
    "def dataset_fingerprint(df: pd.DataFrame, cols=(\"row_id\", COL_PDF, COL_LEVEL, COL_LANG)) -> str:\n",
    "    \"\"\"Stable fingerprint over key fields + model name, to invalidate cache if data/model changes.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    h.update(MODEL_NAME.encode(\"utf-8\"))\n",
    "    for c in cols:\n",
    "        s = \"\\n\".join(map(str, df[c].astype(str).tolist()))\n",
    "        h.update(s.encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _parquet_engine_available() -> bool:\n",
    "    return (\n",
    "        importlib.util.find_spec(\"pyarrow\") is not None\n",
    "        or importlib.util.find_spec(\"fastparquet\") is not None\n",
    "    )\n",
    "\n",
    "def cache_paths(cache_dir: Path, fp: str):\n",
    "    meta = cache_dir / f\"meta_{fp}.json\"\n",
    "    pdf  = cache_dir / f\"emb_pdf_{fp}.npy\"\n",
    "    lvl  = cache_dir / f\"emb_level_{fp}.npy\"\n",
    "    lng  = cache_dir / f\"emb_lang_{fp}.npy\"\n",
    "    rows_parquet = cache_dir / f\"rows_{fp}.parquet\"\n",
    "    rows_csv     = cache_dir / f\"rows_{fp}.csv\"\n",
    "    return meta, pdf, lvl, lng, rows_parquet, rows_csv\n",
    "\n",
    "def save_cache(meta_path: Path, pdf_path: Path, lvl_path: Path, lng_path: Path,\n",
    "               rows_parquet_path: Path, rows_csv_path: Path,\n",
    "               emb_pdf: np.ndarray, emb_level: np.ndarray, emb_lang: np.ndarray,\n",
    "               df_rows: pd.DataFrame):\n",
    "    # Save npy arrays\n",
    "    np.save(pdf_path, emb_pdf)\n",
    "    np.save(lvl_path, emb_level)\n",
    "    np.save(lng_path, emb_lang)\n",
    "\n",
    "    # Sanitize df and write as Parquet if possible else CSV\n",
    "    text_cols = [COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG]\n",
    "    df_rows = sanitize_rows_df(df_rows, text_cols)\n",
    "\n",
    "    rows_format = \"csv\"\n",
    "    if _parquet_engine_available():\n",
    "        try:\n",
    "            import pyarrow as pa, pyarrow.parquet as pq\n",
    "            table = pa.Table.from_pandas(df_rows, preserve_index=False, safe=True)\n",
    "            pq.write_table(table, rows_parquet_path)\n",
    "            rows_format = \"parquet\"\n",
    "        except Exception:\n",
    "            df_rows.to_csv(rows_csv_path, index=False)\n",
    "    else:\n",
    "        df_rows.to_csv(rows_csv_path, index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"created_at\": int(time.time()),\n",
    "        \"num_rows\": int(df_rows.shape[0]),\n",
    "        \"rows_format\": rows_format,\n",
    "        \"schema\": {\n",
    "            \"pdf_col\": COL_PDF, \"level_col\": COL_LEVEL, \"lang_col\": COL_LANG,\n",
    "            \"name_col\": COL_NAME, \"url_col\": COL_URL\n",
    "        }\n",
    "    }\n",
    "    meta_path.write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "def try_load_cache(meta_path: Path, pdf_path: Path, lvl_path: Path, lng_path: Path,\n",
    "                   rows_parquet_path: Path, rows_csv_path: Path):\n",
    "    # check file existence\n",
    "    if not (meta_path.exists() and pdf_path.exists() and lvl_path.exists() and lng_path.exists()):\n",
    "        return None\n",
    "    if not (rows_parquet_path.exists() or rows_csv_path.exists()):\n",
    "        return None\n",
    "    try:\n",
    "        meta = json.loads(meta_path.read_text())\n",
    "        emb_pdf = np.load(pdf_path)\n",
    "        emb_level = np.load(lvl_path)\n",
    "        emb_lang = np.load(lng_path)\n",
    "\n",
    "        fmt = meta.get(\"rows_format\", \"parquet\")\n",
    "        if fmt == \"parquet\" and rows_parquet_path.exists() and _parquet_engine_available():\n",
    "            try:\n",
    "                import pyarrow.parquet as pq\n",
    "                df_rows = pq.read_table(rows_parquet_path).to_pandas()\n",
    "            except Exception:\n",
    "                if rows_csv_path.exists():\n",
    "                    df_rows = pd.read_csv(rows_csv_path)\n",
    "                else:\n",
    "                    return None\n",
    "        elif rows_csv_path.exists():\n",
    "            df_rows = pd.read_csv(rows_csv_path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        return meta, emb_pdf, emb_level, emb_lang, df_rows\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56e7e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache. Rows: 377  Model: sentence-transformers/all-MiniLM-L6-v2  Rows format: parquet\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import time, hashlib\n",
    "# Normalize key columns before fingerprint/embedding\n",
    "df[COL_PDF]   = df[COL_PDF].map(norm_text)\n",
    "df[COL_LEVEL] = df[COL_LEVEL].map(norm_text)\n",
    "df[COL_LANG]  = df[COL_LANG].map(norm_text)\n",
    "\n",
    "fp = dataset_fingerprint(df)\n",
    "meta_path, pdf_path, lvl_path, lng_path, rows_parquet_path, rows_csv_path = cache_paths(CACHE_DIR, fp)\n",
    "\n",
    "loaded = try_load_cache(meta_path, pdf_path, lvl_path, lng_path, rows_parquet_path, rows_csv_path)\n",
    "\n",
    "if loaded is None:\n",
    "    print(\"No valid cache found (or data/model changed). Building embeddings...\")\n",
    "    emb_pdf   = model.encode(df[COL_PDF].tolist(),   convert_to_tensor=False, normalize_embeddings=True)\n",
    "    emb_level = model.encode(df[COL_LEVEL].tolist(), convert_to_tensor=False, normalize_embeddings=True)\n",
    "    emb_lang  = model.encode(df[COL_LANG].tolist(),  convert_to_tensor=False, normalize_embeddings=True)\n",
    "\n",
    "    emb_pdf   = np.asarray(emb_pdf, dtype=\"float32\")\n",
    "    emb_level = np.asarray(emb_level, dtype=\"float32\")\n",
    "    emb_lang  = np.asarray(emb_lang, dtype=\"float32\")\n",
    "\n",
    "    save_cache(\n",
    "        meta_path, pdf_path, lvl_path, lng_path,\n",
    "        rows_parquet_path, rows_csv_path,\n",
    "        emb_pdf, emb_level, emb_lang,\n",
    "        df[[\"row_id\", COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG]]\n",
    "    )\n",
    "    print(\"Cache saved.\")\n",
    "else:\n",
    "    meta, emb_pdf, emb_level, emb_lang, df_cached = loaded\n",
    "    print(f\"Loaded cache. Rows: {meta['num_rows']}  Model: {meta['model']}  Rows format: {meta.get('rows_format')}\")\n",
    "    # Align df to cached row order just in case\n",
    "    df = df.merge(df_cached[[\"row_id\"]], on=\"row_id\", how=\"right\").sort_values(\"row_id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b308ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_to_01(cos_scores: np.ndarray) -> np.ndarray:\n",
    "    # Input may be cosine in [-1,1] if using util.cos_sim; here we use dot since normalized embeddings.\n",
    "    # With normalized vectors, dot product is cosine in [-1,1]. Map to [0,1].\n",
    "    return (cos_scores + 1.0) / 2.0\n",
    "\n",
    "def scores_for_query(query: dict,\n",
    "                     emb_pdf: np.ndarray, emb_level: np.ndarray, emb_lang: np.ndarray,\n",
    "                     df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Query fields\n",
    "    q_look = norm_text(query.get(\"looking_for\",\"\"))\n",
    "    q_level = norm_text(query.get(\"job_level\",\"\"))\n",
    "    q_constraints = norm_text(query.get(\"constraints\",\"\"))\n",
    "    q_language = norm_text(query.get(\"language\",\"\"))\n",
    "\n",
    "    # Embed only provided parts\n",
    "    e_look = model.encode(q_look, convert_to_tensor=False, normalize_embeddings=True) if q_look else None\n",
    "    e_lvl  = model.encode(q_level, convert_to_tensor=False, normalize_embeddings=True) if q_level else None\n",
    "    e_cons = model.encode(q_constraints, convert_to_tensor=False, normalize_embeddings=True) if q_constraints else None\n",
    "    e_lang = model.encode(q_language, convert_to_tensor=False, normalize_embeddings=True) if q_language else None\n",
    "\n",
    "    n = len(df_base)\n",
    "    look_scores = np.full(n, 0.5, dtype=\"float32\")\n",
    "    level_scores = np.full(n, 0.5, dtype=\"float32\")\n",
    "    constraint_scores = np.full(n, 0.5, dtype=\"float32\")\n",
    "    lang_scores = np.full(n, 0.5, dtype=\"float32\")\n",
    "\n",
    "    # With normalized embeddings, matrix @ vector gives cosine; then map to [0,1]\n",
    "    if e_look is not None:\n",
    "        look_scores = cos_to_01(emb_pdf @ e_look)\n",
    "    if e_lvl is not None:\n",
    "        level_scores = cos_to_01(emb_level @ e_lvl)\n",
    "    if e_cons is not None:\n",
    "        constraint_scores = cos_to_01(emb_pdf @ e_cons)\n",
    "    if e_lang is not None:\n",
    "        lang_scores = cos_to_01(emb_lang @ e_lang)\n",
    "\n",
    "    out = df_base.copy()\n",
    "    out[\"looking_for_score\"] = look_scores\n",
    "    out[\"job_level_score\"]   = level_scores\n",
    "    out[\"constraint_score\"]  = constraint_scores\n",
    "    out[\"language_score\"]    = lang_scores\n",
    "\n",
    "    out[\"final_score\"] = (\n",
    "        W_LOOK  * out[\"looking_for_score\"] +\n",
    "        W_CONS  * out[\"constraint_score\"]  +\n",
    "        W_LANG  * out[\"language_score\"]    +\n",
    "        W_LEVEL * out[\"job_level_score\"]\n",
    "    )\n",
    "\n",
    "    # Rank columns for coverage checks\n",
    "    out = out.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "    out[\"rank_final\"] = np.arange(len(out)) + 1\n",
    "    out[\"rank_look\"]  = out[\"looking_for_score\"].rank(ascending=False, method=\"first\")\n",
    "    out[\"rank_cons\"]  = out[\"constraint_score\"].rank(ascending=False, method=\"first\")\n",
    "    out[\"rank_lang\"]  = out[\"language_score\"].rank(ascending=False, method=\"first\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def ensure_coverage(dfw: pd.DataFrame, facet_rank_col: str, facet_present: bool,\n",
    "                    k: int = K_PER_FACET, top_m: int = GUARANTEE_TOP) -> pd.DataFrame:\n",
    "    \"\"\"Guarantee at least one top-k (by facet) item appears in the first top_m of final ranking.\"\"\"\n",
    "    if not facet_present or len(dfw) == 0:\n",
    "        return dfw\n",
    "    top_m_idx = dfw.index[:top_m]\n",
    "    present = any(dfw.loc[i, facet_rank_col] <= k for i in top_m_idx)\n",
    "    if present:\n",
    "        return dfw\n",
    "\n",
    "    cand = dfw[dfw[facet_rank_col] <= k].head(1)\n",
    "    if cand.empty:\n",
    "        return dfw\n",
    "    cand_idx = cand.index[0]\n",
    "    if cand_idx in top_m_idx:\n",
    "        return dfw\n",
    "\n",
    "    # Move candidate into position top_m-1\n",
    "    rows = dfw.iloc[:top_m-1].copy()\n",
    "    head_rest = dfw.iloc[top_m-1:].copy()\n",
    "    cand_row = dfw.loc[[cand_idx]]\n",
    "    dfw = pd.concat([rows, cand_row, head_rest.drop(index=cand_idx, errors=\"ignore\")], axis=0).reset_index(drop=True)\n",
    "    return dfw\n",
    "\n",
    "def recommend(query: dict, df_base: pd.DataFrame,\n",
    "              emb_pdf: np.ndarray, emb_level: np.ndarray, emb_lang: np.ndarray,\n",
    "              top_n=TOP_N) -> pd.DataFrame:\n",
    "    scored = scores_for_query(query, emb_pdf, emb_level, emb_lang, df_base)\n",
    "\n",
    "    # Which facets were provided?\n",
    "    facet_present_look = bool(norm_text(query.get(\"looking_for\",\"\")))\n",
    "    facet_present_cons = bool(norm_text(query.get(\"constraints\",\"\")))\n",
    "    facet_present_lang = bool(norm_text(query.get(\"language\",\"\")))\n",
    "\n",
    "    # Apply coverage guarantees (top-4 must include at least one top-3 by each present facet)\n",
    "    scored = scored.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "    scored[\"rank_look\"] = scored[\"looking_for_score\"].rank(ascending=False, method=\"first\")\n",
    "    scored = ensure_coverage(scored, \"rank_look\", facet_present_look, K_PER_FACET, GUARANTEE_TOP)\n",
    "\n",
    "    scored[\"rank_cons\"] = scored[\"constraint_score\"].rank(ascending=False, method=\"first\")\n",
    "    scored = ensure_coverage(scored, \"rank_cons\", facet_present_cons, K_PER_FACET, GUARANTEE_TOP)\n",
    "\n",
    "    scored[\"rank_lang\"] = scored[\"language_score\"].rank(ascending=False, method=\"first\")\n",
    "    scored = ensure_coverage(scored, \"rank_lang\", facet_present_lang, K_PER_FACET, GUARANTEE_TOP)\n",
    "\n",
    "    cols = [COL_NAME, COL_URL, \"looking_for_score\", \"job_level_score\", \"constraint_score\", \"language_score\", \"final_score\"]\n",
    "    return scored.head(top_n)[cols].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c95cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Query_Restructured import get_assessment_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d095dee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACK] 1/1: {\"ack\":\"received\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'looking_for': 'Looking for new graduates to join the sales team, assessing their communication, problem-solving, and interpersonal skills, along with their general aptitude for a sales role.',\n",
       " 'constraints': 'Average assessment time: 30 mins',\n",
       " 'job_level': 'junior',\n",
       " 'need_to_assess': 'C,B,A,P',\n",
       " 'language': 'unknown'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query = \"\"\"I am new looking for new graduates in my sales team, suggest an 30 min long assessment\n",
    "\n",
    "\"\"\"\n",
    "prompt_new = get_assessment_summary(Query)\n",
    "prompt_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c348dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_url</th>\n",
       "      <th>looking_for_score</th>\n",
       "      <th>job_level_score</th>\n",
       "      <th>constraint_score</th>\n",
       "      <th>language_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales Interview Guide</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/sales-interview-guide/</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.645180</td>\n",
       "      <td>0.541128</td>\n",
       "      <td>0.651462</td>\n",
       "      <td>0.692306</td>\n",
       "      <td>topic=0.74 | constraints=0.54 | language=0.65 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graduate Scenarios</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/graduate-scenarios/</td>\n",
       "      <td>0.712539</td>\n",
       "      <td>0.642156</td>\n",
       "      <td>0.659233</td>\n",
       "      <td>0.651462</td>\n",
       "      <td>0.691397</td>\n",
       "      <td>topic=0.71 | constraints=0.66 | language=0.65 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entry Level Sales Solution</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/entry-level-sales-solution/</td>\n",
       "      <td>0.743897</td>\n",
       "      <td>0.681670</td>\n",
       "      <td>0.509315</td>\n",
       "      <td>0.537414</td>\n",
       "      <td>0.681839</td>\n",
       "      <td>topic=0.74 | constraints=0.51 | language=0.54 | level=0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Graduate Scenarios Profile Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/graduate-scenarios-profile...</td>\n",
       "      <td>0.691794</td>\n",
       "      <td>0.639502</td>\n",
       "      <td>0.628219</td>\n",
       "      <td>0.677320</td>\n",
       "      <td>0.675581</td>\n",
       "      <td>topic=0.69 | constraints=0.63 | language=0.68 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Skills</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/ai-skills/</td>\n",
       "      <td>0.640571</td>\n",
       "      <td>0.544772</td>\n",
       "      <td>0.725695</td>\n",
       "      <td>0.595527</td>\n",
       "      <td>0.639255</td>\n",
       "      <td>topic=0.64 | constraints=0.73 | language=0.60 | level=0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OPQ MQ Sales Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/opq-mq-sales-report/</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.632149</td>\n",
       "      <td>0.541128</td>\n",
       "      <td>0.545375</td>\n",
       "      <td>0.680394</td>\n",
       "      <td>topic=0.74 | constraints=0.54 | language=0.55 | level=0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salesforce Development (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/salesforce-development-new/</td>\n",
       "      <td>0.709146</td>\n",
       "      <td>0.649160</td>\n",
       "      <td>0.632733</td>\n",
       "      <td>0.595527</td>\n",
       "      <td>0.680323</td>\n",
       "      <td>topic=0.71 | constraints=0.63 | language=0.60 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verify Interactive G+ Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/verify-interactive-g-report/</td>\n",
       "      <td>0.706900</td>\n",
       "      <td>0.639502</td>\n",
       "      <td>0.555914</td>\n",
       "      <td>0.677320</td>\n",
       "      <td>0.674555</td>\n",
       "      <td>topic=0.71 | constraints=0.56 | language=0.68 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Graduate Scenarios Narrative Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/graduate-scenarios-narrati...</td>\n",
       "      <td>0.691794</td>\n",
       "      <td>0.628530</td>\n",
       "      <td>0.628219</td>\n",
       "      <td>0.677320</td>\n",
       "      <td>0.674484</td>\n",
       "      <td>topic=0.69 | constraints=0.63 | language=0.68 | level=0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Retail Sales and Service Simulation</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/view/retail-sales-and-service-s...</td>\n",
       "      <td>0.704866</td>\n",
       "      <td>0.681670</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.595527</td>\n",
       "      <td>0.673368</td>\n",
       "      <td>topic=0.70 | constraints=0.58 | language=0.60 | level=0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       assessment_name                                                                   assessment_url  looking_for_score  job_level_score  constraint_score  language_score  final_score                                                         why\n",
       "0                Sales Interview Guide         https://www.shl.com/products/product-catalog/view/sales-interview-guide/           0.740727         0.645180          0.541128        0.651462     0.692306  topic=0.74 | constraints=0.54 | language=0.65 | level=0.65\n",
       "1                   Graduate Scenarios            https://www.shl.com/products/product-catalog/view/graduate-scenarios/           0.712539         0.642156          0.659233        0.651462     0.691397  topic=0.71 | constraints=0.66 | language=0.65 | level=0.64\n",
       "2           Entry Level Sales Solution    https://www.shl.com/products/product-catalog/view/entry-level-sales-solution/           0.743897         0.681670          0.509315        0.537414     0.681839  topic=0.74 | constraints=0.51 | language=0.54 | level=0.68\n",
       "3    Graduate Scenarios Profile Report  https://www.shl.com/products/product-catalog/view/graduate-scenarios-profile...           0.691794         0.639502          0.628219        0.677320     0.675581  topic=0.69 | constraints=0.63 | language=0.68 | level=0.64\n",
       "4                            AI Skills                     https://www.shl.com/products/product-catalog/view/ai-skills/           0.640571         0.544772          0.725695        0.595527     0.639255  topic=0.64 | constraints=0.73 | language=0.60 | level=0.54\n",
       "5                  OPQ MQ Sales Report           https://www.shl.com/products/product-catalog/view/opq-mq-sales-report/           0.740727         0.632149          0.541128        0.545375     0.680394  topic=0.74 | constraints=0.54 | language=0.55 | level=0.63\n",
       "6         Salesforce Development (New)    https://www.shl.com/products/product-catalog/view/salesforce-development-new/           0.709146         0.649160          0.632733        0.595527     0.680323  topic=0.71 | constraints=0.63 | language=0.60 | level=0.65\n",
       "7         Verify Interactive G+ Report   https://www.shl.com/products/product-catalog/view/verify-interactive-g-report/           0.706900         0.639502          0.555914        0.677320     0.674555  topic=0.71 | constraints=0.56 | language=0.68 | level=0.64\n",
       "8  Graduate Scenarios Narrative Report  https://www.shl.com/products/product-catalog/view/graduate-scenarios-narrati...           0.691794         0.628530          0.628219        0.677320     0.674484  topic=0.69 | constraints=0.63 | language=0.68 | level=0.63\n",
       "9  Retail Sales and Service Simulation  https://www.shl.com/products/product-catalog/view/retail-sales-and-service-s...           0.704866         0.681670          0.583235        0.595527     0.673368  topic=0.70 | constraints=0.58 | language=0.60 | level=0.68"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = recommend(prompt_new, df, emb_pdf, emb_level, emb_lang, top_n=TOP_N)\n",
    "\n",
    "def explain_row(r):\n",
    "    return (f\"topic={r['looking_for_score']:.2f} | \"\n",
    "            f\"constraints={r['constraint_score']:.2f} | \"\n",
    "            f\"language={r['language_score']:.2f} | \"\n",
    "            f\"level={r['job_level_score']:.2f}\")\n",
    "\n",
    "results[\"why\"] = results.apply(explain_row, axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f8ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Query  n_true  n_pred  Recall@10 note\n",
      "Based on the JD below recommend me assessment for the Consultant position in my organizations. The assessment should not be more than 90 mins\\nb Description\\n\\n Job Purpose \\n\\nResponsibilities\\n\\nThe Consultant role supports the broader professional services organization by leading the delivery of impactful client solutions and advising on client programs. Consultants are expected to deliver solutions, services, and insights that are driven by industry best practices and that positively impact client business objectives and partnerships. Individuals in this role provide I/O technical guidance to internal and external stakeholders, and drive continuous improvement related to project delivery.  Primary Duties and Responsibilities  Primary job duties and responsibilities include but may not be limited to:\\n\\n Planning, executing, and documenting projects related to clients’ talent assessment and development needs (e.g., job analysis, validation, leadership assessment, succession planning, program implementation, adverse impact analyses, best practices). \\n Leading projects; ensuring overall quality for all client deliverables and guiding other to do the same. \\n Serving as an expert resource to clients and internal stakeholders about issues related to talent assessment, selection, and development. \\n Linking human capital insights to business outcomes and demonstrating ROI. \\n Collaborating with members of the Sales team to manage existing programs and identify new business opportunities. \\n Maintaining up-to-date knowledge of the field including empirical research, industry trends, and competitors. \\n Providing talent analytics and data insights to technical and non-technical stakeholders. \\n Contributing to the ongoing definition and development of SHL’s offerings and methodologies. \\n Presenting to and interacting with senior client stakeholders. \\n Providing thought leadership; working with delivery and commercial teams to drive improvements in the scoping and execution of projects/deliverables. \\n\\n Key Competencies: \\n\\n Decision Making \\n Collaboration \\n Building Relationships \\n Creativity and Innovation \\n Planning and Organizing \\n Delivering Results \\n Adaptability \\n\\n Qualifications include: \\n\\n A graduate degree in Industrial/Organizational psychology or a related discipline \\n 2+ years of relevant work experience in applied talent assessment, talent management, or employee selection, including program design and implementation \\n Client-facing delivery experience with design and implementation of talent assessment programs (including job analysis, criterion validation, content validation, and interviews) \\n Selection system development and / or evaluation \\n Proficient in at least one statistical program (e.g., SPSS, R) \\n Strong communication skills and presenting technical results to non-technical stakeholders \\n\\n#IO #IndustrialPsychology #psychtalent #talentmanagement #talentassessment #psychometrics #consultant\\n\\nAbout Us\\n\\nWe unlock the possibilities of businesses through the power of people, science, and technology.\\n\\nWe started this industry of people insight more than 40 years ago and continue to lead the market with powerhouse product launches, ground-breaking science, and business transformation.\\n\\nWhen you inspire and transform people’s lives, you will experience the greatest business outcomes possible. SHL’s products insights, experiences, and services can help achieve growth at scale.\\n\\nMore at shl.com.\\n\\nWhat SHL Can Offer You\\n\\n An inclusive culture. \\n A fun and flexible workplace where you’ll be inspired to do your best work. \\n Employee benefits package that takes care of you and your family. \\n Support, coaching, and on-the-job development to achieve career success. \\n The ability to transform workplaces around the world for others. \\n\\nSHL is an equal opportunity employer.       5      10   0.000000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ICICI Bank Assistant Admin, Experience required 0-2 years, test should be 30-40 mins long       6      10   0.000000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I want to hire new graduates for a sales role in my company, the budget is for about an hour for each test. Give me some options       9      10   0.000000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         I am looking for a COO for my company in China and I want to see if they are culturally a right fit for our company. Suggest me an assessment that they can complete in about an hour       6      10   0.000000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Content Writer required, expert in English and SEO.       5      10   0.200000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  We're looking for a Marketing Manager who can drive Recro’s brand positioning, community growth, and overall marketing strategy to fuel business growth. The ideal candidate is a strategic thinker, an execution-focused leader, and an expert in building high-performing marketing teams.\\n\\n\\n\\nAbout Recro \\n\\n\\nRecro is a developer-focused platform that was founded to match individual expertise with the right opportunities seamlessly. We empower talented developers by providing them with relevant experience at fast-growing startups based on technical competencies and aspirations. These opportunities have a significant impact on their career success and help them become their best self.\\n\\n\\nAbout The Role\\n\\nDevelop and execute Recro’s marketing strategy to enhance community engagement, brand positioning, and industry presence.\\nLead the marketing team and oversee all functions, with a strong focus on community building, events, brand positioning, social media engagement, and market intelligence.\\nDrive demand generation by leveraging community-driven initiatives, influencer partnerships, and strategic event participation.\\nOrganize and represent Recro at industry conferences, networking events, and developer meetups to strengthen brand positioning.\\nBuild and nurture relationships with industry influencers, developer communities, and partners to create brand advocates.\\nOwn the marketing funnel, ensuring continuous tracking, analysis, and optimization of community engagement and event performance.\\nCollaborate with sales, business development, and leadership teams to align marketing strategies with business objectives and market trends.\\nManage marketing budgets, prioritizing event sponsorships, partnerships, and community-driven growth initiatives.\\nDevelop compelling content strategies to drive community interaction and thought leadership.\\nStay ahead of industry trends, competitor movements, and emerging social and market intelligence to maintain a competitive edge\\n\\n\\nRequirements\\n\\n5+ years of experience in B2B marketing with a strong focus on community building, events, and brand positioning.\\nHas a deep understanding how demand generation works from traditional and new age channels\\nProven track record of executing large-scale events and community-driven initiatives.\\nExperience in developing partnerships with industry influencers and thought leaders.\\nStrong understanding of social media dynamics and community engagement strategies.\\nAbility to leverage market intelligence and competitor insights to refine marketing strategies.\\nExceptional storytelling and brand communication skills.\\nHands-on experience with event management, sponsorships, and partnership collaborations.\\nExperience in building a thriving developer or tech community is a plus.\\nOpen for flexible work timings as per target geographies.\\n\\nI have no bar on duration.       5      10   0.200000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I want to hire a Senior Data Analyst with 5 years of experience and expertise in SQL, Excel and Python. The assessment can be 1-2 hour long      10      10   0.300000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Find me 1 hour long assesment for the below job at SHL\\nJob Description\\n\\n Join a community that is shaping the future of work! SHL, People Science. People Answers. \\n\\nAre you a seasoned QA Engineer with a flair for innovation? Are you ready to shape the future of talent assessment and empower organizations to unlock their full potential? If so, we want you to be a part of the SHL Team! As a QA Engineer, you will be involved in creating and implementing software solutions that contribute to the development of our ground-breaking products.\\n\\nAn excellent benefit package is offered in a culture where career development, with ongoing manager guidance, collaboration, flexibility, diversity, and inclusivity are all intrinsic to our culture.  There is a huge investment in SHL currently so there’s no better time to become a part of something transformational.\\n\\nWhat You Will Be Doing\\n\\n Getting involved in engineering quality assurance and providing inputs when required. \\n Create and develop test plans for various forms of testing. \\n Conducts and/or participates in formal and informal test case reviews. \\n Develop and initiate functional tests and regression tests. \\n Rolling out improvements for testing and quality processes. \\n\\nEssential\\n\\n What we are looking for from you: \\n\\n Development experience – Java or JavaScript, CSS, HTML (Automation) \\n Selenium WebDriver and page object design pattern (Automation) \\n SQL server knowledge \\n Test case management experience. \\n Manual Testing \\n\\nDesirable\\n\\n Knowledge the basic concepts of testing \\n Strong solution-finding experience \\n Strong verbal and written communicator. \\n\\nGet In Touch\\n\\nFind out how this one-off opportunity can help you achieve your career goals by making an application to our knowledgeable and friendly Talent Acquisition team. Choose a new path with SHL.\\n\\n #CareersAtSHL #SHLHiringTalent \\n\\n#TechnologyJobs #QualityAssuranceJobs\\n\\n#CareerOpportunities #JobOpportunities \\n\\nAbout Us\\n\\nWe unlock the possibilities of businesses through the power of people, science and technology.\\nWe started this industry of people insight more than 40 years ago and continue to lead the market with powerhouse product launches, ground-breaking science and business transformation.\\nWhen you inspire and transform people’s lives, you will experience the greatest business outcomes possible. SHL’s products insights, experiences, and services can help achieve growth at scale.\\n\\nWhat SHL Can Offer You\\n\\nDiversity, equity, inclusion and accessibility are key threads in the fabric of SHL’s business and culture (find out more about DEI and accessibility at SHL )\\nEmployee benefits package that takes care of you and your family.\\nSupport, coaching, and on-the-job development to achieve career success\\nA fun and flexible workplace where you’ll be inspired to do your best work (find out more LifeAtSHL )\\nThe ability to transform workplaces around the world for others.\\n\\nSHL is an equal opportunity employer. We support and encourage applications from a diverse range of candidates. We can, and do make adjustments to make sure our recruitment process is as inclusive as possible.\\n\\nSHL is an equal opportunity employer.       9      10   0.333333     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        KEY RESPONSIBITILES:\\n\\nManage the sound-scape of the station through appropriate creative and marketing interventions to Increase or Maintain the listenership\\nActs as an interface between Programming & sales team, thereby supporting the sales team by providing creative inputs in order to increase the overall ad spends by clients\\nBuild brand Mirchi by ideating fresh programming initiatives on air campaigns, programming led on-ground events & new properties to ensure brand differentiation & thus increase brand recall at station level\\nInvest time in local RJs to grow & develop them as local celebrities\\nThrough strong networking, must focus on identifying the best of local talent and ensure to bring the creative minds from the market on board with Mirchi\\nBuild radio as a category for both listeners & advertisers\\nPeople Management\\nIdentifying the right talent and investing time in developing them by frequent feedback on their performance\\nMonitor, Coach and mentor team members on a regular basis\\nDevelopment of Jocks as per guidelines\\nMust have an eye to spot the local talent to fill up vacancies locally\\n\\n\\n\\n\\nTECHNICAL SKILLS & QUALIFICATION REQUIRED:\\n\\nGraduation / Post Graduation (Any specialisation) with 8 -12 years of relevant experience\\nExperience in digital content conceptualisation\\nStrong branding focus\\nMust be well-read in variety of areas and must keep up with the latest events in the city / cluster / country\\nMust know to read, write & speak English \\n\\n\\nPERSONAL ATTRIBUTES:\\n\\nExcellent communication skills\\nGood interpersonal skills\\nPeople management\\n\\n\\nSuggest me some tests for the above jd. The duration should be at most 90 mins       5      10   0.400000     \n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I am hiring for Java developers who can also collaborate effectively with my business teams. Looking for an assessment(s) that can be completed in 40 minutes.       5      10   0.600000     \n",
      "\n",
      "=== Mean Recall@10 over 10 queries: 0.2033 ===\n"
     ]
    }
   ],
   "source": [
    "# ==== SHL Recall@10 Evaluation (slug-based, cached, retry/backoff) ====\n",
    "# Assumes you already have in memory:\n",
    "#   - df, emb_pdf, emb_level, emb_lang\n",
    "#   - functions: get_assessment_summary(text: str) and recommend(prompt, df, emb_pdf, emb_level, emb_lang, top_n=10)\n",
    "# Ground truth file path:\n",
    "GROUND_TRUTH_PATH = r\"C:\\Users\\vinee\\Downloads\\Gen_AI Dataset.xlsx\"\n",
    "\n",
    "\n",
    "# =================== CONFIG ===================\n",
    "K = 10                    # Recall@K\n",
    "DEFAULT_TOP_N = 10        # How many results to request from your model (min K)\n",
    "REQUEST_DELAY_SEC = 0.6   # Pacing between calls to avoid RPM/QPS limits\n",
    "MAX_RETRIES = 5           # Max retries on 429\n",
    "BASE_BACKOFF = 2.0        # Base seconds for exponential backoff\n",
    "CACHE_PATH = \"pred_cache.json\"\n",
    "CACHE_VERSION = \"v1\"      # <-- bump this whenever you change prompts/model/logic\n",
    "FORCE_REFRESH_ALL = True # Set True to bypass cache for all queries this run\n",
    "MODEL_NAME = \"gemini-2.5-flash\"        # optional metadata for cache key\n",
    "PROMPT_PRESET = \"summary_default_v1\"    # optional metadata for cache key\n",
    "\n",
    "# Optional: import Google's 429 exception if available\n",
    "try:\n",
    "    from google.api_core.exceptions import ResourceExhausted\n",
    "except Exception:\n",
    "    ResourceExhausted = None\n",
    "\n",
    "# =================== UTILITIES ===================\n",
    "def normalize_url(u: Any) -> str:\n",
    "    \"\"\"Lowercase, strip, strip scheme, 'www.', trailing slash.\"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return \"\"\n",
    "    u = u.strip().lower()\n",
    "    u = u.replace(\"https://\", \"\").replace(\"http://\", \"\")\n",
    "    if u.startswith(\"www.\"):\n",
    "        u = u[4:]\n",
    "    if u.endswith(\"/\"):\n",
    "        u = u[:-1]\n",
    "    return u\n",
    "\n",
    "def extract_slug(u: Any) -> str:\n",
    "    \"\"\"Return a stable identifier (prefers '/view/<slug>', else last path segment).\"\"\"\n",
    "    u = normalize_url(u)\n",
    "    m = re.search(r\"/view/([^/?#]+)\", u)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    parts = [p for p in u.split(\"/\") if p]\n",
    "    return parts[-1] if parts else u\n",
    "\n",
    "def recall_at_k(true_items: Set[str], pred_items: List[str], k: int) -> float:\n",
    "    if not true_items:\n",
    "        return 0.0\n",
    "    return len(set(pred_items[:k]) & true_items) / len(true_items)\n",
    "\n",
    "# =================== CACHE ===================\n",
    "def _cache_load() -> Dict[str, List[str]]:\n",
    "    if os.path.exists(CACHE_PATH):\n",
    "        try:\n",
    "            with open(CACHE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                return json.load(f)\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _cache_save(cache: Dict[str, List[str]]):\n",
    "    tmp = CACHE_PATH + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp, CACHE_PATH)\n",
    "\n",
    "def _qkey(query_text: str) -> str:\n",
    "    \"\"\"Cache key: version + model/prompt metadata + K/N + query text.\"\"\"\n",
    "    base = f\"{CACHE_VERSION}|{MODEL_NAME}|{PROMPT_PRESET}|K={K}|N={DEFAULT_TOP_N}|{query_text}\"\n",
    "    return sha1(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# =================== MODEL CALL WRAPPER ===================\n",
    "def get_predictions_for_query(query_text: str,\n",
    "                              top_n: int = DEFAULT_TOP_N,\n",
    "                              force_refresh: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Calls your pipeline with retry/backoff and returns list of predicted slugs.\n",
    "    Uses disk cache to avoid repeat API usage for the same query.\n",
    "    \"\"\"\n",
    "    top_n = max(top_n, K)\n",
    "    cache = _cache_load()\n",
    "    key = _qkey(query_text)\n",
    "\n",
    "    if not (force_refresh or FORCE_REFRESH_ALL):\n",
    "        if key in cache:\n",
    "            return cache[key]\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Build prompt (your function)\n",
    "            prompt = get_assessment_summary(query_text)\n",
    "            # Call your recommender (expects DataFrame with 'assessment_url' column)\n",
    "            res = recommend(prompt, df, emb_pdf, emb_level, emb_lang, top_n=top_n)\n",
    "\n",
    "            if not isinstance(res, pd.DataFrame) or 'assessment_url' not in res.columns:\n",
    "                preds = []\n",
    "            else:\n",
    "                preds = res['assessment_url'].astype(str).map(extract_slug).tolist()\n",
    "\n",
    "            cache[key] = preds\n",
    "            _cache_save(cache)\n",
    "\n",
    "            # Pacing to respect RPM/QPS\n",
    "            time.sleep(REQUEST_DELAY_SEC)\n",
    "            return preds\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            # Detect 429\n",
    "            is_429 = False\n",
    "            if ResourceExhausted and isinstance(e, ResourceExhausted):\n",
    "                is_429 = True\n",
    "            elif \"ResourceExhausted\" in str(e) or \"429\" in str(e):\n",
    "                is_429 = True\n",
    "\n",
    "            if is_429 and attempt < MAX_RETRIES - 1:\n",
    "                sleep_s = BASE_BACKOFF * (2 ** attempt) + random.uniform(0, 0.5)\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "            else:\n",
    "                # Save empty to avoid hammering API on repeated runs\n",
    "                cache[key] = []\n",
    "                _cache_save(cache)\n",
    "                break\n",
    "\n",
    "    return []\n",
    "\n",
    "# =================== LOAD GROUND TRUTH ===================\n",
    "gt = pd.read_excel(GROUND_TRUTH_PATH)  # expects columns: Query, Assessment_url\n",
    "if not set([\"Query\", \"Assessment_url\"]).issubset(gt.columns):\n",
    "    raise ValueError(f\"Ground truth must have columns ['Query','Assessment_url']; found {list(gt.columns)}\")\n",
    "\n",
    "gt = gt.copy()\n",
    "gt[\"Assessment_url\"] = gt[\"Assessment_url\"].astype(str).map(normalize_url)\n",
    "gt[\"slug\"] = gt[\"Assessment_url\"].map(extract_slug)\n",
    "gt_dict: Dict[str, Set[str]] = gt.groupby(\"Query\")[\"slug\"].apply(set).to_dict()\n",
    "\n",
    "# =================== EVALUATE ===================\n",
    "rows = []\n",
    "for q in gt_dict.keys():\n",
    "    pred_slugs = get_predictions_for_query(q, top_n=DEFAULT_TOP_N)\n",
    "    r = recall_at_k(gt_dict[q], pred_slugs, K)\n",
    "    rows.append({\n",
    "        \"Query\": q,\n",
    "        \"n_true\": len(gt_dict[q]),\n",
    "        \"n_pred\": len(pred_slugs),\n",
    "        \"Recall@10\": r,\n",
    "        \"note\": \"\" if pred_slugs else \"no_predictions (possibly quota/retry-exhausted or cached empty)\"\n",
    "    })\n",
    "\n",
    "per_query_df = pd.DataFrame(rows).sort_values(\"Recall@10\", ascending=True).reset_index(drop=True)\n",
    "mean_recall_10 = per_query_df[\"Recall@10\"].mean() if not per_query_df.empty else 0.0\n",
    "\n",
    "# Nicely print results (truncate long queries)\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n",
    "print(per_query_df[[\"Query\",\"n_true\",\"n_pred\",\"Recall@10\",\"note\"]].to_string(index=False))\n",
    "print(f\"\\n=== Mean Recall@10 over {len(per_query_df)} queries: {mean_recall_10:.4f} ===\")\n",
    "\n",
    "# =================== QUICK HOW-TO ===================\n",
    "# - To force fresh predictions for ALL queries this run: set FORCE_REFRESH_ALL = True at the top.\n",
    "# - To version the cache when you change prompts/model: bump CACHE_VERSION.\n",
    "# - To pace more (avoid 429): increase REQUEST_DELAY_SEC (e.g., 1.0–1.5).\n",
    "# - To wipe cache entirely: \n",
    "#     import os; \n",
    "#     os.remove(\"pred_cache.json\") if os.path.exists(\"pred_cache.json\") else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aad2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"pred_cache.json\"):\n",
    "    os.remove(\"pred_cache.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17d565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shl_env (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

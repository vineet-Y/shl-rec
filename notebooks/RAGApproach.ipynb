{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "969311fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019cafb",
   "metadata": {},
   "source": [
    "####Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71aca2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinee\\Desktop\\Graph_RAG_Project\\shl_env\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os, re, json, time, math, random\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Set\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "from scipy import sparse\n",
    "\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9d623",
   "metadata": {},
   "source": [
    "#### Setting Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074b2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: configuration\n",
    "\n",
    "# ---- Paths (EDIT THESE) ----\n",
    "DATASET_JSON_PATH = r\"Assessment_Dataset_cleaned.json\"   # your catalog file\n",
    "TRAIN_JSON_PATH   = r\"Train_Dataset_SHL.json\"        # your labeled queries file\n",
    "\n",
    "# ---- Gemini ----\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "GEMINI_API_KEY = \"AIzaSyB0NcVO-mbW50HzrEJ0wz0llmISRpqkx50\"  ## Key deactivated before uploading jupyter file\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not set in environment.\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# ---- Retrieval model ----\n",
    "SBERT_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# ---- Dataset columns (new schema) ----\n",
    "COL_NAME   = \"name\"\n",
    "COL_URL    = \"url\"\n",
    "COL_PDF    = \"pdf_text\"\n",
    "COL_LEVEL  = \"job_level\"\n",
    "COL_LANG   = \"test_language\"\n",
    "COL_ADAPT  = \"adaptive_support\"\n",
    "COL_DESC   = \"description\"\n",
    "COL_DUR    = \"duration\"\n",
    "COL_TYPE   = \"test_type\"\n",
    "COL_REMOTE = \"remote_support\"\n",
    "\n",
    "# ---- Weights for scoring ----\n",
    "W_EMB_LOOK   = 0.75\n",
    "W_EMB_LEVEL  = 0.10\n",
    "W_EMB_LANG   = 0.10\n",
    "W_TFIDF_LOOK = 0.15\n",
    "\n",
    "# ---- LLM re-ranker ----\n",
    "TOP_K_FOR_LLM   = 25\n",
    "FINAL_K         = 10\n",
    "LITE_DESC_CHARS = 600\n",
    "\n",
    "# ---- Cache ----\n",
    "CACHE_DIR = Path(\"./cache\")\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182b944",
   "metadata": {},
   "source": [
    "##### Normalizing queries and simplifying url daat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b672f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def norm_text(x) -> str:\n",
    "    if isinstance(x, list):\n",
    "        x = \" \".join(map(str, x))\n",
    "    elif isinstance(x, dict):\n",
    "        x = json.dumps(x, ensure_ascii=False)\n",
    "    elif x is None:\n",
    "        x = \"\"\n",
    "    else:\n",
    "        x = str(x)\n",
    "    x = x.strip()\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    return x\n",
    "\n",
    "def yn_norm(val: str) -> str:\n",
    "    v = (str(val or \"\")).strip().lower()\n",
    "    if v in {\"yes\",\"true\",\"y\",\"1\"}: return \"Yes\"\n",
    "    if v in {\"no\",\"false\",\"n\",\"0\"}: return \"No\"\n",
    "    return \"Yes\" if \"yes\" in v else (\"No\" if \"no\" in v else (val or \"\"))\n",
    "\n",
    "def normalize_url(u: Any) -> str:\n",
    "    if not isinstance(u, str): return \"\"\n",
    "    s = u.strip()\n",
    "    s = re.sub(r\"[#?].*$\", \"\", s)\n",
    "    if s.endswith(\"/\"): s = s[:-1]\n",
    "    s = s.replace(\"https://\",\"\").replace(\"http://\",\"\").lower()\n",
    "    if s.startswith(\"www.\"): s = s[4:]\n",
    "    return s\n",
    "\n",
    "def extract_slug(u: Any) -> str:\n",
    "    s = normalize_url(u)\n",
    "    m = re.search(r\"/view/([^/]+)$\", s)\n",
    "    if m: return m.group(1)\n",
    "    parts = [p for p in s.split(\"/\") if p]\n",
    "    return parts[-1] if parts else s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9de89b",
   "metadata": {},
   "source": [
    "##### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e247752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: 374 rows\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: load dataset JSON and normalize\n",
    "\n",
    "def load_dataset_json(path: str) -> pd.DataFrame:\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    assert isinstance(data, list), \"Dataset must be a JSON array.\"\n",
    "    df = pd.DataFrame(data).fillna(\"\")\n",
    "\n",
    "    # Ensure required columns exist and are normalized\n",
    "    for c in [COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG, COL_ADAPT, COL_DESC, COL_REMOTE]:\n",
    "        df[c] = df.get(c, \"\").map(norm_text) if c in df.columns else \"\"\n",
    "\n",
    "    if COL_DUR in df.columns:\n",
    "        def _to_int(v):\n",
    "            try: return int(float(str(v).strip()))\n",
    "            except: return \"\"\n",
    "        df[COL_DUR] = df[COL_DUR].map(_to_int)\n",
    "    else:\n",
    "        df[COL_DUR] = \"\"\n",
    "\n",
    "    if COL_TYPE in df.columns:\n",
    "        df[COL_TYPE] = df[COL_TYPE].map(lambda x: x if isinstance(x, list)\n",
    "                                        else [t.strip() for t in str(x).split(\",\") if t.strip()])\n",
    "    else:\n",
    "        df[COL_TYPE] = [[]]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_dataset_json(DATASET_JSON_PATH)\n",
    "print(f\"Loaded dataset: {df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c79c05",
   "metadata": {},
   "source": [
    "##### LOading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625bea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings + TF-IDF from cache...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dataset_fingerprint(df: pd.DataFrame, cols=(COL_PDF, COL_LEVEL, COL_LANG)) -> str:\n",
    "    import hashlib\n",
    "    h = hashlib.sha256()\n",
    "    h.update(SBERT_MODEL_NAME.encode(\"utf-8\"))\n",
    "    for c in cols:\n",
    "        s = \"\\n\".join(map(str, df[c].astype(str).tolist()))\n",
    "        h.update(s.encode(\"utf-8\", errors=\"ignore\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "def save_cache(fp: str, emb_pdf, emb_level, emb_lang, tfidf_mat, tfidf_vocab):\n",
    "    np.save(CACHE_DIR/f\"emb_pdf_{fp}.npy\", emb_pdf)\n",
    "    np.save(CACHE_DIR/f\"emb_level_{fp}.npy\", emb_level)\n",
    "    np.save(CACHE_DIR/f\"emb_lang_{fp}.npy\", emb_lang)\n",
    "    sparse.save_npz(CACHE_DIR/f\"tfidf_{fp}.npz\", tfidf_mat)\n",
    "    Path(CACHE_DIR/f\"tfidf_vocab_{fp}.json\").write_text(\n",
    "        json.dumps({k:int(v) for k,v in tfidf_vocab.items()}, ensure_ascii=False),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "def load_cache(fp: str):\n",
    "    try:\n",
    "        emb_pdf   = np.load(CACHE_DIR/f\"emb_pdf_{fp}.npy\")\n",
    "        emb_level = np.load(CACHE_DIR/f\"emb_level_{fp}.npy\")\n",
    "        emb_lang  = np.load(CACHE_DIR/f\"emb_lang_{fp}.npy\")\n",
    "        tfidf_mat = sparse.load_npz(CACHE_DIR/f\"tfidf_{fp}.npz\")\n",
    "        vocab     = json.loads(Path(CACHE_DIR/f\"tfidf_vocab_{fp}.json\").read_text(encoding=\"utf-8\"))\n",
    "        return emb_pdf, emb_level, emb_lang, tfidf_mat, vocab\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "fp = dataset_fingerprint(df)\n",
    "cached = load_cache(fp)\n",
    "\n",
    "if cached is None:\n",
    "    print(\"Building embeddings + TF-IDF (first time)...\")\n",
    "    sbert = SentenceTransformer(SBERT_MODEL_NAME)\n",
    "\n",
    "    emb_pdf   = sbert.encode(df[COL_PDF].tolist(),   convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "    emb_level = sbert.encode(df[COL_LEVEL].tolist(), convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "    emb_lang  = sbert.encode(df[COL_LANG].tolist(),  convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=100_000)\n",
    "    tfidf_mat = tfidf.fit_transform(df[COL_PDF].tolist())\n",
    "    tfidf_mat = sk_normalize(tfidf_mat, norm=\"l2\", copy=False)\n",
    "\n",
    "    save_cache(fp, emb_pdf, emb_level, emb_lang, tfidf_mat, tfidf.vocabulary_)\n",
    "else:\n",
    "    print(\"Loading embeddings + TF-IDF from cache...\")\n",
    "    emb_pdf, emb_level, emb_lang, tfidf_mat, tfidf_vocab = cached\n",
    "    tfidf = TfidfVectorizer(vocabulary=tfidf_vocab, ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d559ab2",
   "metadata": {},
   "source": [
    "Making Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514caa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cos01(x: np.ndarray) -> np.ndarray:\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def _tfidf_sim(qtext: str) -> np.ndarray:\n",
    "    \"\"\"Compute TF-IDF similarity between a query and dataset PDF text.\"\"\"\n",
    "    if not qtext:\n",
    "        return np.zeros(df.shape[0], dtype=\"float32\")\n",
    "\n",
    "    # Use stored vocabulary safely\n",
    "    vocab = None\n",
    "    try:\n",
    "        # Try to use the vocabulary from the global tfidf object if available\n",
    "        if hasattr(tfidf, \"vocabulary_\") and tfidf.vocabulary_:\n",
    "            vocab = tfidf.vocabulary_\n",
    "        elif hasattr(tfidf, \"vocabulary\") and tfidf.vocabulary:\n",
    "            vocab = tfidf.vocabulary\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if vocab is None:\n",
    "        raise RuntimeError(\"TF-IDF vocabulary not initialized or loaded from cache incorrectly.\")\n",
    "\n",
    "    vec = TfidfVectorizer(vocabulary=vocab, ngram_range=(1, 2))\n",
    "    qv = vec.fit_transform([qtext])\n",
    "    sims = (tfidf_mat @ qv.T).toarray().ravel().astype(\"float32\")\n",
    "\n",
    "    if sims.max() > 0:\n",
    "        sims /= sims.max()\n",
    "    return sims\n",
    "\n",
    "\n",
    "def score_candidates(q: Dict[str,str]) -> pd.DataFrame:\n",
    "    q_look = norm_text(q.get(\"looking_for\",\"\"))\n",
    "    q_lvl  = norm_text(q.get(\"job_level\",\"\"))\n",
    "    q_lang = norm_text(q.get(\"language\",\"\"))\n",
    "\n",
    "    sbert = SentenceTransformer(SBERT_MODEL_NAME)\n",
    "\n",
    "    e_look = sbert.encode(q_look, convert_to_tensor=False, normalize_embeddings=True) if q_look else None\n",
    "    e_lvl  = sbert.encode(q_lvl,  convert_to_tensor=False, normalize_embeddings=True) if q_lvl  else None\n",
    "    e_lang = sbert.encode(q_lang, convert_to_tensor=False, normalize_embeddings=True) if q_lang else None\n",
    "\n",
    "    n = len(df)\n",
    "    s_look = np.full(n, 0.5, dtype=\"float32\")\n",
    "    s_lvl  = np.full(n, 0.5, dtype=\"float32\")\n",
    "    s_lang = np.full(n, 0.5, dtype=\"float32\")\n",
    "\n",
    "    if e_look is not None: s_look = _cos01(emb_pdf   @ e_look)\n",
    "    if e_lvl  is not None: s_lvl  = _cos01(emb_level @ e_lvl)\n",
    "    if e_lang is not None: s_lang = _cos01(emb_lang  @ e_lang)\n",
    "\n",
    "    s_look_lex = _tfidf_sim(q_look)\n",
    "\n",
    "    final = (\n",
    "        W_EMB_LOOK   * s_look +\n",
    "        W_EMB_LEVEL  * s_lvl  +\n",
    "        W_EMB_LANG   * s_lang +\n",
    "        W_TFIDF_LOOK * s_look_lex\n",
    "    )\n",
    "\n",
    "    out = df[[COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG, COL_DESC, COL_ADAPT, COL_REMOTE, COL_DUR, COL_TYPE]].copy()\n",
    "    out[\"score_topic\"] = s_look\n",
    "    out[\"score_level\"] = s_lvl\n",
    "    out[\"score_lang\"]  = s_lang\n",
    "    out[\"score_lex\"]   = s_look_lex\n",
    "    out[\"final_score\"] = final\n",
    "    out = out.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ebbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SYSTEM_INSTRUCTION = \"\"\"\n",
    "You will receive a hiring query or job description in multiple parts.\n",
    "Ingest each PART silently. Do NOT produce the final answer until you receive 'END'.\n",
    "When you receive 'END', output ONLY valid JSON with exactly these keys (all values as strings):\n",
    "{\n",
    "  \"looking_for\": \"string\",\n",
    "  \"instructions\": \"string\",\n",
    "  \"job_level\": \"string\",\n",
    "  \"language\": \"string\"\n",
    "}\n",
    "Heuristics:\n",
    "- If skills are not directly present, infer the most relevant skills for the job role/position; mention them in 'looking_for', for example if it is a bank fob Financial and numerical skills are needed.\n",
    "- Do NOT mention candidate experience inside 'looking_for'; focus on skills/role/what to assess.\n",
    "- Ensure key terms present in the query/JD appear in 'looking_for'.\n",
    "- In 'instructions', capture constraints: time limits, sittings, test type, required language(s), job-level constraints.\n",
    "- If language not stated, 'language' must be empty.\n",
    "- Normalize job_level to one of: entry-level, mid, senior, executive, director, mid-professional, unknown.\n",
    "- Output must be compact; no newlines inside values; no explanations outside JSON.\n",
    "Until 'END', reply only with a tiny ACK JSON like {\"ack\":\"part i/N received\"}.\n",
    "\"\"\"\n",
    "\n",
    "def _extract_text(resp) -> Optional[str]:\n",
    "    try:\n",
    "        for cand in (getattr(resp, \"candidates\", []) or []):\n",
    "            content = getattr(cand, \"content\", None)\n",
    "            if not content: continue\n",
    "            for part in (getattr(content, \"parts\", []) or []):\n",
    "                if getattr(part, \"text\", None):\n",
    "                    return part.text\n",
    "        try: return resp.text\n",
    "        except Exception: return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _force_json(raw: str) -> Dict[str, str]:\n",
    "    m = re.search(r\"\\{[\\s\\S]*?\\}\", raw or \"\")\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in response\")\n",
    "    data = json.loads(m.group(0))\n",
    "    out = {\n",
    "        \"looking_for\": str(data.get(\"looking_for\",\"\")).strip(),\n",
    "        \"instructions\": str(data.get(\"instructions\",\"\")).strip(),\n",
    "        \"job_level\": str(data.get(\"job_level\",\"\")).strip(),\n",
    "        \"language\": str(data.get(\"language\",\"\")).strip(),\n",
    "    }\n",
    "    # normalize job level\n",
    "    jl = out[\"job_level\"].lower()\n",
    "    if any(k in jl for k in [\"entry\",\"fresher\",\"junior\",\"graduate\"]): out[\"job_level\"] = \"entry-level\"\n",
    "    elif \"mid-professional\" in jl: out[\"job_level\"] = \"mid-professional\"\n",
    "    elif any(k in jl for k in [\"mid\",\"intermediate\"]): out[\"job_level\"] = \"mid\"\n",
    "    elif \"director\" in jl: out[\"job_level\"] = \"director\"\n",
    "    elif any(k in jl for k in [\"executive\",\"cxo\",\"chief\",\"vp\",\"svp\",\"evp\"]): out[\"job_level\"] = \"executive\"\n",
    "    elif any(k in jl for k in [\"senior\",\"lead\",\"principal\",\"staff\"]): out[\"job_level\"] = \"senior\"\n",
    "    else: out[\"job_level\"] = \"unknown\"\n",
    "\n",
    "    if not out[\"language\"] or out[\"language\"].lower() in {\"n/a\",\"na\",\"none\",\"unknown\"}:\n",
    "        out[\"language\"] = \"\"\n",
    "\n",
    "    for k in list(out.keys()):\n",
    "        out[k] = re.sub(r\"\\s*\\n+\\s*\", \" \", out[k]).strip()\n",
    "\n",
    "    return out\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = 4000) -> List[str]:\n",
    "    paras = [p.strip() for p in re.split(r\"\\n{2,}\", text) if p.strip()]\n",
    "    chunks, buf = [], \"\"\n",
    "    for p in paras:\n",
    "        if len(buf) + len(p) + 2 <= max_chars:\n",
    "            buf = (buf + \"\\n\\n\" + p) if buf else p\n",
    "        else:\n",
    "            if buf: chunks.append(buf)\n",
    "            buf = p\n",
    "    if buf: chunks.append(buf)\n",
    "    final = []\n",
    "    for c in chunks:\n",
    "        if len(c) <= max_chars:\n",
    "            final.append(c)\n",
    "        else:\n",
    "            for i in range(0, len(c), max_chars):\n",
    "                final.append(c[i:i+max_chars])\n",
    "    return final\n",
    "\n",
    "def _with_retry_send(chat, msg, cfg, tries=3, backoff=2.0):\n",
    "    last_err = None\n",
    "    for t in range(tries):\n",
    "        try:\n",
    "            return chat.send_message(msg, generation_config=cfg)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if t < tries - 1:\n",
    "                time.sleep(backoff * (2 ** t))\n",
    "            else:\n",
    "                raise last_err\n",
    "\n",
    "def get_assessment_summary(text: str, verbose: bool=False) -> Dict[str, str]:\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME, system_instruction=SYSTEM_INSTRUCTION)\n",
    "    chat = model.start_chat(history=[])\n",
    "\n",
    "    chunks = chunk_text(text, max_chars=4000)\n",
    "    N = len(chunks)\n",
    "\n",
    "    ack_cfg = {\"temperature\": 0.0, \"max_output_tokens\": 64, \"response_mime_type\": \"application/json\"}\n",
    "    for i, part in enumerate(chunks, 1):\n",
    "        msg = f\"PART {i}/{N}\\n\\n{part}\\n\\nACK only; final JSON after 'END'.\"\n",
    "        resp = _with_retry_send(chat, msg, ack_cfg, tries=3, backoff=2.0)\n",
    "        if verbose:\n",
    "            print(f\"[ACK] {i}/{N}: {_extract_text(resp) or ''}\")\n",
    "\n",
    "    final_prompt = (\n",
    "        \"END\\n\\nNow output ONLY the JSON object described earlier. \"\n",
    "        \"No commentary. If your previous attempt was cut off, continue here and return the full JSON.\"\n",
    "    )\n",
    "    final_cfg = {\"temperature\": 0.0, \"max_output_tokens\": 2048, \"response_mime_type\": \"application/json\"}\n",
    "\n",
    "    final = _with_retry_send(chat, final_prompt, final_cfg, tries=3, backoff=2.0)\n",
    "    raw = _extract_text(final)\n",
    "\n",
    "    if not raw:\n",
    "        retry = _with_retry_send(chat, \"Return the JSON now. Only the JSON.\", final_cfg, tries=2, backoff=3.0)\n",
    "        raw = _extract_text(retry)\n",
    "\n",
    "    if not raw:\n",
    "        raise RuntimeError(\"Gemini returned no text in the final step.\")\n",
    "    return _force_json(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LLM re-ranker (indices only), Gives 10 outputs\n",
    "\n",
    "def call_llm_reranker(prompt: str) -> str:\n",
    "    # Simple Gemini call; return raw text\n",
    "    try:\n",
    "        model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "        resp = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\"temperature\": 0.2, \"max_output_tokens\": 512}\n",
    "        )\n",
    "        return getattr(resp, \"text\", \"\") or \"\"\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def candidate_payload_lite(row: pd.Series, idx: int) -> dict:\n",
    "    return {\n",
    "        \"idx\":          int(idx),\n",
    "        \"name\":         row.get(COL_NAME, \"\"),\n",
    "        \"duration\":     row.get(COL_DUR, \"\"),\n",
    "        \"job_level\":    row.get(COL_LEVEL, \"\"),\n",
    "        \"language\":     row.get(COL_LANG, \"\"),\n",
    "        \"description\":  str(row.get(COL_DESC, \"\"))[:LITE_DESC_CHARS],\n",
    "    }\n",
    "\n",
    "def llm_select_top10_idx(updated_query: str, items: List[dict]) -> List[int]:\n",
    "    instruction = f\"\"\"\n",
    "You are an assessment selection assistant.\n",
    "\n",
    "UPDATED QUERY (user intent):\n",
    "{updated_query}\n",
    "\n",
    "You will receive up to {TOP_K_FOR_LLM} candidate assessments, each with:\n",
    "- idx (integer),\n",
    "- name,\n",
    "- duration (minutes),\n",
    "- job_level,\n",
    "- language,\n",
    "- short description.\n",
    "\n",
    "Task:\n",
    "- Select EXACTLY 10 indices (idx) that best satisfy the UPDATED QUERY.\n",
    "- Balance topic/skills (based on description/name), job level, and language.\n",
    "- make sure you cover all the skills from the UPDATED QUERY\n",
    "- If at least 10 candidates exist, you MUST return 10.\n",
    "\n",
    "Return ONLY JSON (no extra text):\n",
    "{{\"selected_idx\":[i1,i2,...]}}\n",
    "\"\"\"\n",
    "    payload = {\"candidates\": items}\n",
    "    prompt  = instruction + \"\\nCANDIDATES_JSON:\\n\" + json.dumps(payload, ensure_ascii=False)\n",
    "\n",
    "    raw = call_llm_reranker(prompt)\n",
    "    try:\n",
    "        i, j = raw.find(\"{\"), raw.rfind(\"}\")\n",
    "        data = json.loads(raw[i:j+1]) if (i!=-1 and j!=-1 and j>i) else {}\n",
    "        arr = data.get(\"selected_idx\", [])\n",
    "        out, seen = [], set()\n",
    "        for v in arr:\n",
    "            try:\n",
    "                iv = int(str(v).strip())\n",
    "                if iv not in seen:\n",
    "                    out.append(iv); seen.add(iv)\n",
    "            except: \n",
    "                pass\n",
    "        return out[:FINAL_K]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def _format_rows(df_sel: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    for _, r in df_sel.iterrows():\n",
    "        rows.append({\n",
    "            \"url\":              r.get(COL_URL, \"\"),\n",
    "            \"name\":             r.get(COL_NAME, \"\"),\n",
    "            \"adaptive support\": yn_norm(r.get(COL_ADAPT, \"\")),\n",
    "            \"description\":      r.get(COL_DESC, \"\"),\n",
    "            \"duration\":         str(r.get(COL_DUR, \"\")),\n",
    "            \"remote_support\":   yn_norm(r.get(COL_REMOTE, \"\")),\n",
    "            \"test_type\":        r.get(COL_TYPE, []) if isinstance(r.get(COL_TYPE, []), list)\n",
    "                                else [t.strip() for t in str(r.get(COL_TYPE, \"\")).split(\",\") if t.strip()]\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def recommend_v2(query_text: str) -> List[Dict[str, Any]]:\n",
    "    # 1) LLM summary\n",
    "    summary = get_assessment_summary(query_text)\n",
    "    q = {\n",
    "        \"looking_for\": summary.get(\"looking_for\",\"\"),\n",
    "        \"instructions\": summary.get(\"instructions\",\"\"),\n",
    "        \"job_level\": summary.get(\"job_level\",\"\"),\n",
    "        \"language\": summary.get(\"language\",\"\"),\n",
    "    }\n",
    "\n",
    "    # 2) retrieve & score\n",
    "    ranked = score_candidates(q)\n",
    "    top25  = ranked.head(TOP_K_FOR_LLM).copy().reset_index(drop=True)\n",
    "    top25[\"__idx\"] = top25.index\n",
    "\n",
    "    # 3) lite LLM pack\n",
    "    updated_query = (q[\"looking_for\"] + \" \" + q[\"instructions\"]).strip()\n",
    "    items_for_llm = [candidate_payload_lite(row, int(row[\"__idx\"])) for _, row in top25.iterrows()]\n",
    "\n",
    "    # 4) ask LLM for indices\n",
    "    selected_idx = llm_select_top10_idx(updated_query, items_for_llm)\n",
    "\n",
    "    # 5) backfill to 10\n",
    "    if len(selected_idx) < FINAL_K:\n",
    "        seen = set(selected_idx)\n",
    "        for i in top25[\"__idx\"].tolist():\n",
    "            if i not in seen:\n",
    "                selected_idx.append(int(i)); seen.add(int(i))\n",
    "            if len(selected_idx) >= FINAL_K:\n",
    "                break\n",
    "\n",
    "    # 6) order per LLM (then by score as tie-break)\n",
    "    pos = {i: p for p, i in enumerate(selected_idx)}\n",
    "    chosen = top25[top25[\"__idx\"].isin(selected_idx)].copy()\n",
    "    chosen[\"__order\"] = chosen[\"__idx\"].map(pos)\n",
    "    chosen = chosen.sort_values([\"__order\",\"final_score\"], ascending=[True, False]).drop(columns=[\"__order\",\"__idx\"])\n",
    "\n",
    "    return _format_rows(chosen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62d53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: recall utilities\n",
    "\n",
    "def predicted_urls_from_results(results: Any, k: int = 10) -> List[str]:\n",
    "    urls = []\n",
    "    if isinstance(results, list):\n",
    "        for r in results[:k]:\n",
    "            if isinstance(r, dict):\n",
    "                urls.append(str(r.get(\"url\",\"\")))\n",
    "            else:\n",
    "                urls.append(str(r))\n",
    "    return urls\n",
    "\n",
    "def recall_at_k(true_items: Set[str], pred_items: List[str], k: int = 10) -> float:\n",
    "    if not true_items:\n",
    "        return 0.0\n",
    "    return len(set(pred_items[:k]) & true_items) / len(true_items)\n",
    "\n",
    "def short_q(q: str, n: int = 25) -> str:\n",
    "    q = q or \"\"\n",
    "    return q[:n] + (\"…\" if len(q) > n else \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e166dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.shl.com/products/product-catalog/view/python-new/',\n",
       "  'name': 'Python (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of Python programming, databases, modules and library.',\n",
       "  'duration': '11',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/html5-new/',\n",
       "  'name': 'HTML5 (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of HTML5 and its application in creating a user interface.',\n",
       "  'duration': '11',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/automata-new/',\n",
       "  'name': 'Automata (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'An AI-powered coding simulation assessment that evaluates candidate’s programming ability. Offers a familiar IDE environment available in over 40 different programming languages and tests candidates using real-world coding problems. Your use of this assessment product may be subject to New York City Law 144 (Regulation of the Use of Automated Employment Decision Tools) (dated July 5, 2023). Compliance with Law 144 is your responsibility. Read more on https://www.shl.com/legal/shl-us-regulatory-compliance/',\n",
       "  'duration': '',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Simulations']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/automata-pro-new/',\n",
       "  'name': 'Automata Pro (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'An AI-powered coding simulation assessment that evaluates candidate’s programming ability. Offers a familiar IDE environment available in over 40 different programming languages and tests candidates using real-world coding problems. Your use of this assessment product may be subject to New York City Law 144 (Regulation of the Use of Automated Employment Decision Tools) (dated July 5, 2023). Compliance with Law 144 is your responsibility. Read more on https://www.shl.com/legal/shl-us-regulatory-compliance/',\n",
       "  'duration': '',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Simulations']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/c-programming-new-4122/',\n",
       "  'name': 'C++ Programming (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of programming in the C++ language and the ability to use the C++ standard library to write code.',\n",
       "  'duration': '10',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/perl-new/',\n",
       "  'name': 'Perl (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of Perl scripting used for text manipulation, web development, system administration, etc.',\n",
       "  'duration': '9',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/automata-front-end/',\n",
       "  'name': 'Automata Front End',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Simulation based test that measures the front-end development capabilities using HTML, CSS, and JavaScript. The candidate is provided with 3 different sections to code in HTML, CSS and JavaScript respectively and a separate output section to view the output. This simulation is then manually scored.',\n",
       "  'duration': '30',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Simulations']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/swing-new/',\n",
       "  'name': 'Swing (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of components, containers, layouts and event handling in Swing.',\n",
       "  'duration': '4',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/net-xaml-new/',\n",
       "  'name': '.NET XAML (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge of XAML triggers, data binding, custom controls and layouts.',\n",
       "  'duration': '5',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']},\n",
       " {'url': 'https://www.shl.com/products/product-catalog/view/ado-net-new/',\n",
       "  'name': 'ADO.NET (New)',\n",
       "  'adaptive support': 'No',\n",
       "  'description': 'Multi-choice test that measures the knowledge on the concepts of ADO.NET architecture, components and data provider objects.',\n",
       "  'duration': '10',\n",
       "  'remote_support': 'Yes',\n",
       "  'test_type': ['Knowledge & Skills']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_v2(\"Hiring for Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f5c3a",
   "metadata": {},
   "source": [
    "Calculating RAG Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb575d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [1/10] Evaluating query: I am hiring for Java developers who can also collaborate effectively with my bus...\n",
      "Recall@10 = 0.600\n",
      "\n",
      "=== [2/10] Evaluating query: I am looking for a COO for my company in China and I want to see if they are cul...\n",
      "Recall@10 = 0.500\n",
      "\n",
      "=== [3/10] Evaluating query: KEY RESPONSIBITILES:\n",
      "\n",
      "Manage the sound-scape of the station through appropriate ...\n",
      "Recall@10 = 0.400\n",
      "\n",
      "=== [4/10] Evaluating query: Content Writer required, expert in English and SEO....\n",
      "Recall@10 = 0.600\n",
      "\n",
      "=== [5/10] Evaluating query: Find me 1 hour long assesment for the below job at SHL\n",
      "Job Description\n",
      "\n",
      " Join a ...\n",
      "Recall@10 = 0.556\n",
      "\n",
      "=== [6/10] Evaluating query: Based on the JD below recommend me assessment for the Consultant position in my ...\n",
      "Recall@10 = 0.000\n",
      "\n",
      "=== [7/10] Evaluating query: ICICI Bank Assistant Admin, Experience required 0-2 years, test should be 30-40 ...\n",
      "Recall@10 = 0.000\n",
      "\n",
      "=== [8/10] Evaluating query: We're looking for a Marketing Manager who can drive Recro’s brand positioning, c...\n",
      "Recall@10 = 0.200\n",
      "\n",
      "=== [9/10] Evaluating query: I want to hire a Senior Data Analyst with 5 years of experience and expertise in...\n",
      "Recall@10 = 0.500\n",
      "\n",
      "=== [10/10] Evaluating query: I want to hire new graduates for a sales role in my company, the budget is for a...\n",
      "Recall@10 = 0.222\n",
      "\n",
      "=== Individual Recall@10 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Recall@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am hiring for Java developers who can also c...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am looking for a COO for my company in China...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KEY RESPONSIBITILES:\\n\\nManage the sound-scape...</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Content Writer required, expert in English and...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Find me 1 hour long assesment for the below jo...</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Based on the JD below recommend me assessment ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICICI Bank Assistant Admin, Experience require...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We're looking for a Marketing Manager who can ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I want to hire a Senior Data Analyst with 5 ye...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I want to hire new graduates for a sales role ...</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  Recall@10\n",
       "0  I am hiring for Java developers who can also c...   0.600000\n",
       "1  I am looking for a COO for my company in China...   0.500000\n",
       "2  KEY RESPONSIBITILES:\\n\\nManage the sound-scape...   0.400000\n",
       "3  Content Writer required, expert in English and...   0.600000\n",
       "4  Find me 1 hour long assesment for the below jo...   0.555556\n",
       "5  Based on the JD below recommend me assessment ...   0.000000\n",
       "6  ICICI Bank Assistant Admin, Experience require...   0.000000\n",
       "7  We're looking for a Marketing Manager who can ...   0.200000\n",
       "8  I want to hire a Senior Data Analyst with 5 ye...   0.500000\n",
       "9  I want to hire new graduates for a sales role ...   0.222222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mean Recall@10 over 10 queries: 0.3578 ===\n"
     ]
    }
   ],
   "source": [
    "import json, time, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Utility Functions\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def normalize_url(u: str) -> str:\n",
    "    \"\"\"Normalize URLs for comparison (remove scheme, www, trailing slashes).\"\"\"\n",
    "    if not isinstance(u, str):\n",
    "        return \"\"\n",
    "    u = u.strip().lower()\n",
    "    u = re.sub(r\"^https?://\", \"\", u)\n",
    "    if u.startswith(\"www.\"):\n",
    "        u = u[4:]\n",
    "    if u.endswith(\"/\"):\n",
    "        u = u[:-1]\n",
    "    return u\n",
    "\n",
    "def extract_slug(u: str) -> str:\n",
    "    \"\"\"Extract the last meaningful path part as unique slug.\"\"\"\n",
    "    u = normalize_url(u)\n",
    "    m = re.search(r\"/view/([^/?#]+)\", u)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    parts = [p for p in u.split(\"/\") if p]\n",
    "    return parts[-1] if parts else u\n",
    "\n",
    "def recall_at_k(true_urls, pred_urls, k=10):\n",
    "    \"\"\"Compute Recall@K.\"\"\"\n",
    "    true_set = {extract_slug(u) for u in true_urls}\n",
    "    pred_set = {extract_slug(u) for u in pred_urls[:k]}\n",
    "    if not true_set:\n",
    "        return 0.0\n",
    "    return len(true_set & pred_set) / len(true_set)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Evaluation Loop\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "TRAIN_JSON_PATH = \"Train_Dataset_SHL.json\"  # <-- update path if needed\n",
    "\n",
    "with open(TRAIN_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "results = []  # store recall per query\n",
    "\n",
    "for i, item in enumerate(train_data):\n",
    "    query = item[\"Query\"]\n",
    "    true_urls = item.get(\"assessment_url\", [])\n",
    "    \n",
    "    print(f\"\\n=== [{i+1}/{len(train_data)}] Evaluating query: {query[:80]}...\")\n",
    "\n",
    "    try:\n",
    "        # Generate recommendations\n",
    "        recs = recommend_v2(query)\n",
    "        pred_urls = [r[\"url\"] for r in recs]\n",
    "        r_at_10 = recall_at_k(true_urls, pred_urls, k=10)\n",
    "        results.append({\"Query\": query[:80] + (\"...\" if len(query) > 80 else \"\"), \"Recall@10\": r_at_10})\n",
    "        print(f\"Recall@10 = {r_at_10:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query: {e}\")\n",
    "        results.append({\"Query\": query[:80] + (\"...\" if len(query) > 80 else \"\"), \"Recall@10\": 0.0})\n",
    "    \n",
    "    # wait before next query (Gemini safety)\n",
    "    time.sleep(10)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Summary\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "df_recall = pd.DataFrame(results)\n",
    "mean_recall = df_recall[\"Recall@10\"].mean() if not df_recall.empty else 0.0\n",
    "\n",
    "print(\"\\n=== Individual Recall@10 ===\")\n",
    "display(df_recall)\n",
    "\n",
    "print(f\"\\n=== Mean Recall@10 over {len(df_recall)} queries: {mean_recall:.4f} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35338003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shl_env (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb897a26",
   "metadata": {},
   "source": [
    "#### Importing Librariries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed once:\n",
    "# !pip install -q pandas numpy sentence-transformers scikit-learn regex\n",
    "\n",
    "import re, json, math, hashlib, time, importlib.util\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "from scipy import sparse\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f771c",
   "metadata": {},
   "source": [
    "#### Setting Prameters(weights, Model, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf7e7002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "\n",
    "# ==== PATHS ====\n",
    "DATA_JSON  = \"NewSHLDataset.json\"  \n",
    "CACHE_DIR  = Path(\"./embedding_cache\"); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== MODEL ====\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# ==== COLUMN NAMES (align to your JSON keys) ====\n",
    "COL_PDF   = \"pdf_text\"\n",
    "COL_LEVEL = \"job_level\"\n",
    "COL_LANG  = \"test_language\"\n",
    "COL_NAME  = \"assessment_name\"\n",
    "COL_URL   = \"assessment_url\"\n",
    "\n",
    "# RANKING WEIGHTS (semantic all steps; small lexical boost)\n",
    "W_EMB_LOOK  = 0.65  # looking_for ↔ pdf_text\n",
    "W_EMB_CONS  = 0.15  # constraints ↔ pdf_text\n",
    "W_EMB_LANG  = 0.10  # language ↔ language\n",
    "W_EMB_LEVEL = 0.10  # job_level ↔ job_level\n",
    "\n",
    "W_TFIDF_LOOK = 0.20 # lexical boost for looking_for topic\n",
    "W_TFIDF_CONS = 0.10 # lexical boost for constraints\n",
    "\n",
    "# COVERAGE / OUTPUT\n",
    "TOP_N         = 20\n",
    "GUARANTEE_TOP = 4   # ensure coverage in top-4\n",
    "K_PER_FACET   = 3   # from top-3 by facet, if missing in top-4, bring one up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed208d40",
   "metadata": {},
   "source": [
    "#### Loading Assessments Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcf68b",
   "metadata": {},
   "source": [
    "The Dataset is extracted by crawling the SHL website and includes “individual test solutions” only, the dataset has columns assessment_name, assessment_url, pdf_text, job_level, test_type, test_language.\n",
    "Extraction was done from Product fact Sheet pdf and web page of an assessment using PyMuPDf parser and HTML Parser. Further detail commented in Dataset_Extraction.py, the python file can be rerun to extract the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911810bf",
   "metadata": {},
   "source": [
    "In the dataset, pdf_text stores all info from Product Fact Sheet, we will primarily use this data to understand the Assessment Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de9f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(377, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_url</th>\n",
       "      <th>pdf_text</th>\n",
       "      <th>job_level</th>\n",
       "      <th>test_type</th>\n",
       "      <th>test_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Global Skills Development Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>This report is designed to be given to individ...</td>\n",
       "      <td>[Director, Entry-Level, Executive, General Pop...</td>\n",
       "      <td>[Ability &amp; Aptitude, Biodata &amp; Situational Jud...</td>\n",
       "      <td>[English (USA)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>.NET Framework 4.5</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>The.NET Framework 4.5 test measures knowledge ...</td>\n",
       "      <td>[Mid-Professional, Professional Individual Con...</td>\n",
       "      <td>[Knowledge &amp; Skills]</td>\n",
       "      <td>[English (USA)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                   assessment_name  \\\n",
       "0       0  Global Skills Development Report   \n",
       "1       1                .NET Framework 4.5   \n",
       "\n",
       "                                      assessment_url  \\\n",
       "0  https://www.shl.com/products/product-catalog/v...   \n",
       "1  https://www.shl.com/products/product-catalog/v...   \n",
       "\n",
       "                                            pdf_text  \\\n",
       "0  This report is designed to be given to individ...   \n",
       "1  The.NET Framework 4.5 test measures knowledge ...   \n",
       "\n",
       "                                           job_level  \\\n",
       "0  [Director, Entry-Level, Executive, General Pop...   \n",
       "1  [Mid-Professional, Professional Individual Con...   \n",
       "\n",
       "                                           test_type    test_language  \n",
       "0  [Ability & Aptitude, Biodata & Situational Jud...  [English (USA)]  \n",
       "1                               [Knowledge & Skills]  [English (USA)]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_catalog(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    assert p.exists(), f\"File not found: {path}\"\n",
    "    # Try JSONL first (common for large dumps)\n",
    "    try:\n",
    "        rows = []\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if not line: \n",
    "                    continue\n",
    "                try:\n",
    "                    rows.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    # Not JSONL; fall back to array parsing below\n",
    "                    rows = None\n",
    "                    break\n",
    "        if rows is not None:\n",
    "            return pd.DataFrame(rows)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback: full JSON array\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    if isinstance(data, dict) and \"items\" in data:\n",
    "        data = data[\"items\"]\n",
    "    assert isinstance(data, list), \"Top-level JSON must be a list of objects\"\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = load_json_catalog(DATA_JSON)\n",
    "df = df.fillna(\"\")\n",
    "df = df.reset_index(drop=False).rename(columns={\"index\":\"row_id\"})\n",
    "print(df.shape)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c97b6",
   "metadata": {},
   "source": [
    "Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e18c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_text(x) -> str:\n",
    "    \"\"\"Normalize any text/list/dict into a compact single-line string.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = \" \".join(map(str, x))\n",
    "    elif isinstance(x, dict):\n",
    "        x = json.dumps(x, ensure_ascii=False)\n",
    "    elif x is None:\n",
    "        x = \"\"\n",
    "    else:\n",
    "        x = str(x)\n",
    "    x = x.strip()\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    return x\n",
    "\n",
    "# Apply to key columns (handles your sample lists in job_level/test_language)\n",
    "for c in [COL_PDF, COL_LEVEL, COL_LANG, COL_NAME, COL_URL]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].map(norm_text)\n",
    "    else:\n",
    "        df[c] = \"\"  # ensure column exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2ecaf",
   "metadata": {},
   "source": [
    "#### Making Embedding Cache & TF-IDF cache (build once, reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cache: rows=377, model=sentence-transformers/all-MiniLM-L6-v2, rows_format=parquet\n"
     ]
    }
   ],
   "source": [
    "def parquet_available():\n",
    "    return (importlib.util.find_spec(\"pyarrow\") is not None\n",
    "            or importlib.util.find_spec(\"fastparquet\") is not None)\n",
    "\n",
    "def dataset_fingerprint(df: pd.DataFrame, cols=(\"row_id\", COL_PDF, COL_LEVEL, COL_LANG)) -> str:\n",
    "    \"\"\"Stable fingerprint over key fields + model, to invalidate cache on data/model change.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    h.update(MODEL_NAME.encode(\"utf-8\"))\n",
    "    for c in cols:\n",
    "        s = \"\\n\".join(map(str, df[c].astype(str).tolist()))\n",
    "        h.update(s.encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "def cache_paths(cache_dir: Path, fp: str):\n",
    "    meta = cache_dir / f\"meta_{fp}.json\"\n",
    "    np_pdf  = cache_dir / f\"emb_pdf_{fp}.npy\"\n",
    "    np_lvl  = cache_dir / f\"emb_level_{fp}.npy\"\n",
    "    np_lng  = cache_dir / f\"emb_lang_{fp}.npy\"\n",
    "    rows_parquet = cache_dir / f\"rows_{fp}.parquet\"\n",
    "    rows_csv     = cache_dir / f\"rows_{fp}.csv\"\n",
    "    tfidf_pdf    = cache_dir / f\"tfidf_pdf_{fp}.npz\"\n",
    "    tfidf_vocab  = cache_dir / f\"tfidf_vocab_{fp}.json\"\n",
    "    return meta, np_pdf, np_lvl, np_lng, rows_parquet, rows_csv, tfidf_pdf, tfidf_vocab\n",
    "\n",
    "def sanitize_rows_df(df_rows: pd.DataFrame, text_cols: List[str]) -> pd.DataFrame:\n",
    "    out = df_rows.copy()\n",
    "    for c in text_cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].map(norm_text).astype(object)\n",
    "    if \"row_id\" in out.columns:\n",
    "        out[\"row_id\"] = out[\"row_id\"].astype(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _utf8_write_text(path: str | Path, data: str):\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # normalize to NFC to reduce weird ligatures; if still present, UTF-8 handles them\n",
    "    data = unicodedata.normalize(\"NFC\", data)\n",
    "    with p.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "def _utf8_to_csv(df, path):\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # Use UTF-8 with BOM for Excel friendliness on Windows\n",
    "    df.to_csv(p, index=False, encoding=\"utf-8-sig\", line_terminator=\"\\n\")\n",
    "\n",
    "def _parquet_available():\n",
    "    return (importlib.util.find_spec(\"pyarrow\") is not None\n",
    "            or importlib.util.find_spec(\"fastparquet\") is not None)\n",
    "\n",
    "def save_cache(meta_path, np_pdf, np_lvl, np_lng,\n",
    "               rows_parquet, rows_csv,\n",
    "               emb_pdf, emb_level, emb_lang,\n",
    "               df_rows, tfidf_matrix, tfidf_vocab_path, vocab_dict):\n",
    "    # --- save embeddings ---\n",
    "    np.save(np_pdf, emb_pdf); np.save(np_lvl, emb_level); np.save(np_lng, emb_lang)\n",
    "\n",
    "    # --- save TF-IDF ---\n",
    "    # you already have a separate tfidf_pdf path in your caller; keep using that\n",
    "    # (if not, derive from tfidf_vocab_path similarly to earlier patch)\n",
    "    tfidf_pdf_path = Path(str(tfidf_vocab_path).replace(\"tfidf_vocab_\", \"tfidf_pdf_\")).with_suffix(\".npz\")\n",
    "    sparse.save_npz(tfidf_pdf_path, tfidf_matrix)\n",
    "\n",
    "    # vocab may contain numpy ints; coerce to plain int and write as UTF-8 JSON\n",
    "    vocab_plain = {str(k): int(v) for k, v in vocab_dict.items()}\n",
    "    _utf8_write_text(tfidf_vocab_path, json.dumps(vocab_plain, ensure_ascii=False))\n",
    "\n",
    "    # --- sanitize rows then write parquet/CSV ---\n",
    "    def _to_str(x):\n",
    "        if isinstance(x, list):  x = \" \".join(map(str, x))\n",
    "        elif isinstance(x, dict): x = json.dumps(x, ensure_ascii=False)\n",
    "        elif x is None: x = \"\"\n",
    "        else: x = str(x)\n",
    "        return unicodedata.normalize(\"NFC\", x)\n",
    "\n",
    "    text_cols = [COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG]\n",
    "    rows = df_rows.copy()\n",
    "    for c in text_cols:\n",
    "        if c in rows.columns:\n",
    "            rows[c] = rows[c].map(_to_str).astype(object)\n",
    "    if \"row_id\" in rows.columns:\n",
    "        rows[\"row_id\"] = rows[\"row_id\"].astype(int)\n",
    "\n",
    "    rows_format = \"csv\"\n",
    "    if _parquet_available():\n",
    "        try:\n",
    "            import pyarrow as pa, pyarrow.parquet as pq\n",
    "            table = pa.Table.from_pandas(rows, preserve_index=False, safe=True)\n",
    "            pq.write_table(table, rows_parquet)\n",
    "            rows_format = \"parquet\"\n",
    "        except Exception:\n",
    "            _utf8_to_csv(rows, rows_csv)\n",
    "    else:\n",
    "        _utf8_to_csv(rows, rows_csv)\n",
    "\n",
    "    meta = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"created_at\": int(time.time()),\n",
    "        \"num_rows\": int(rows.shape[0]),\n",
    "        \"rows_format\": rows_format,\n",
    "        \"tfidf_npz\": str(tfidf_pdf_path)\n",
    "    }\n",
    "    _utf8_write_text(meta_path, json.dumps(meta, ensure_ascii=False, indent=2))\n",
    "\n",
    "def try_load_cache(meta_path, np_pdf, np_lvl, np_lng,\n",
    "                   rows_parquet, rows_csv, tfidf_pdf, tfidf_vocab):\n",
    "    p_meta, p_pdf, p_lvl, p_lng = map(Path, [meta_path, np_pdf, np_lvl, np_lng])\n",
    "    if not (p_meta.exists() and p_pdf.exists() and p_lvl.exists() and p_lng.exists()):\n",
    "        return None\n",
    "    if not (Path(rows_parquet).exists() or Path(rows_csv).exists()):\n",
    "        return None\n",
    "    if not (Path(tfidf_pdf).exists() and Path(tfidf_vocab).exists()):\n",
    "        return None\n",
    "    try:\n",
    "        meta = json.loads(Path(meta_path).read_text(encoding=\"utf-8\"))\n",
    "        emb_pdf   = np.load(np_pdf)\n",
    "        emb_level = np.load(np_lvl)\n",
    "        emb_lang  = np.load(np_lng)\n",
    "\n",
    "        if meta.get(\"rows_format\") == \"parquet\" and Path(rows_parquet).exists() and _parquet_available():\n",
    "            import pyarrow.parquet as pq\n",
    "            df_rows = pq.read_table(rows_parquet).to_pandas()\n",
    "        else:\n",
    "            df_rows = pd.read_csv(rows_csv, encoding=\"utf-8-sig\")\n",
    "\n",
    "        from scipy import sparse as _sp\n",
    "        tfidf_mat = _sp.load_npz(tfidf_pdf)\n",
    "        vocab_raw = json.loads(Path(tfidf_vocab).read_text(encoding=\"utf-8\"))\n",
    "        vocab = {str(k): int(v) for k, v in vocab_raw.items()}\n",
    "\n",
    "        return meta, emb_pdf, emb_level, emb_lang, df_rows, tfidf_mat, vocab\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Build or load cache\n",
    "fp = dataset_fingerprint(df)\n",
    "meta_path, np_pdf, np_lvl, np_lng, rows_parquet, rows_csv, tfidf_pdf, tfidf_vocab = cache_paths(CACHE_DIR, fp)\n",
    "\n",
    "loaded = try_load_cache(meta_path, np_pdf, np_lvl, np_lng, rows_parquet, rows_csv, tfidf_pdf, tfidf_vocab)\n",
    "\n",
    "if loaded is None:\n",
    "    print(\"No valid cache. Building embeddings + TF-IDF...\")\n",
    "    emb_pdf   = model.encode(df[COL_PDF].tolist(),   convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "    emb_level = model.encode(df[COL_LEVEL].tolist(), convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "    emb_lang  = model.encode(df[COL_LANG].tolist(),  convert_to_tensor=False, normalize_embeddings=True).astype(\"float32\")\n",
    "\n",
    "    # TF-IDF over pdf_text (lexical signal)\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_features=100_000)\n",
    "    tfidf_mat = tfidf.fit_transform(df[COL_PDF].tolist())\n",
    "    tfidf_mat = normalize(tfidf_mat, norm=\"l2\", copy=False)\n",
    "    vocab = tfidf.vocabulary_\n",
    "\n",
    "    save_cache(meta_path, np_pdf, np_lvl, np_lng,\n",
    "               rows_parquet, rows_csv,\n",
    "               emb_pdf, emb_level, emb_lang,\n",
    "               df[[\"row_id\", COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG]],\n",
    "               tfidf_mat, tfidf_vocab, vocab)\n",
    "    print(\"Cache saved.\")\n",
    "else:\n",
    "    meta, emb_pdf, emb_level, emb_lang, df_cached, tfidf_mat, vocab = loaded\n",
    "    print(f\"Loaded cache: rows={meta['num_rows']}, model={meta['model']}, rows_format={meta['rows_format']}\")\n",
    "    # Align df to cached order if needed\n",
    "    df = df.merge(df_cached[[\"row_id\"]], on=\"row_id\", how=\"right\").sort_values(\"row_id\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e3254",
   "metadata": {},
   "source": [
    "Domain priors (to boost recall for implied skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c9b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_HINTS: Dict[str, List[str]] = {\n",
    "    \"coo\": [\"leadership\", \"strategic thinking\", \"decision making\", \"people management\", \"operations excellence\"],\n",
    "    \"chief operating officer\": [\"leadership\", \"strategy\", \"stakeholder management\", \"problem solving\", \"communication\"],\n",
    "    \"engineering manager\": [\"leadership\", \"planning\", \"communication\", \"mentoring\"],\n",
    "    \"product manager\": [\"prioritization\", \"stakeholder management\", \"communication\", \"analytical thinking\"],\n",
    "    \"data scientist\": [\"statistics\", \"machine learning\", \"python\", \"sql\", \"experimentation\"],\n",
    "    # extend over time (active learning)\n",
    "}\n",
    "\n",
    "SKILL_SYNONYMS: Dict[str, List[str]] = {\n",
    "    \"sql\": [\"structured query language\", \"database querying\", \"rdbms\"],\n",
    "    \"c++\": [\"c plus plus\", \"cpp\"],\n",
    "    \"javascript\": [\"js\", \"ecmascript\"],\n",
    "    \"python\": [\"py\"],  # (optional: add pandas/numpy later if it helps)\n",
    "    \"leadership\": [\"people leadership\", \"team leadership\", \"influencing\"],\n",
    "    \"aptitude\": [\"logical reasoning\", \"numerical reasoning\", \"verbal reasoning\"],\n",
    "    \"behavior\": [\"work style\", \"personality\", \"culture fit\"],\n",
    "}\n",
    "\n",
    "def expand_text_with_hints(looking_for: str, job_level: str, need_to_assess: str) -> str:\n",
    "    base = looking_for.lower()\n",
    "    expansions = []\n",
    "\n",
    "    # role-based hints\n",
    "    for k, v in ROLE_HINTS.items():\n",
    "        if k in base:\n",
    "            expansions.extend(v)\n",
    "\n",
    "    # skill synonyms\n",
    "    tokens = re.findall(r\"[a-z0-9\\+\\#\\.]+\", base)\n",
    "    for t in tokens:\n",
    "        if t in SKILL_SYNONYMS:\n",
    "            expansions.extend(SKILL_SYNONYMS[t])\n",
    "\n",
    "    # seniority nudge\n",
    "    if job_level.lower() in {\"senior\",\"lead\",\"principal\",\"executive\"}:\n",
    "        expansions.extend([\"advanced\", \"complex scenarios\"])\n",
    "\n",
    "    # category letters nudge\n",
    "    if \"A\" in need_to_assess: expansions.extend([\"aptitude\", \"reasoning\", \"numerical\", \"verbal\"])\n",
    "    if \"P\" in need_to_assess: expansions.extend([\"personality\", \"work style\", \"culture fit\"])\n",
    "    if \"C\" in need_to_assess: expansions.extend([\"communication\", \"collaboration\", \"leadership\", \"problem solving\"])\n",
    "\n",
    "    expansions = list(dict.fromkeys(expansions))  # dedupe\n",
    "    return looking_for + (\" | HINTS: \" + \", \".join(expansions) if expansions else \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2137bb17",
   "metadata": {},
   "source": [
    "Scoring (semantic all steps + small TF-IDF boost) & Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3601dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_to_01(x: np.ndarray) -> np.ndarray:\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def tfidf_query_vector(text: str, vocab: Dict[str,int]) -> sparse.csr_matrix:\n",
    "    vec = TfidfVectorizer(vocabulary=vocab, ngram_range=(1,2))\n",
    "    return vec.fit_transform([text])\n",
    "\n",
    "def score_query(query: dict) -> pd.DataFrame:\n",
    "    q_look = norm_text(query.get(\"looking_for\",\"\"))\n",
    "    q_cons = norm_text(query.get(\"constraints\",\"\"))\n",
    "    q_lvl  = norm_text(query.get(\"job_level\",\"\"))\n",
    "    q_lang = norm_text(query.get(\"language\",\"\"))\n",
    "    q_need = norm_text(query.get(\"need_to_assess\",\"\"))\n",
    "\n",
    "    # expand looking_for with priors\n",
    "    q_look_expanded = expand_text_with_hints(q_look, q_lvl, q_need)\n",
    "\n",
    "    # embeddings (normalized) → cosine via dot\n",
    "    e_look = model.encode(q_look_expanded, convert_to_tensor=False, normalize_embeddings=True) if q_look_expanded else None\n",
    "    e_cons = model.encode(q_cons,           convert_to_tensor=False, normalize_embeddings=True) if q_cons else None\n",
    "    e_lvl  = model.encode(q_lvl,            convert_to_tensor=False, normalize_embeddings=True) if q_lvl else None\n",
    "    e_lang = model.encode(q_lang,           convert_to_tensor=False, normalize_embeddings=True) if q_lang else None\n",
    "\n",
    "    n = len(df)\n",
    "    s_look = np.full(n, 0.5, dtype=\"float32\")\n",
    "    s_cons = np.full(n, 0.5, dtype=\"float32\")\n",
    "    s_lvl  = np.full(n, 0.5, dtype=\"float32\")\n",
    "    s_lang = np.full(n, 0.5, dtype=\"float32\")\n",
    "\n",
    "    if e_look is not None: s_look = cos_to_01(emb_pdf @ e_look)\n",
    "    if e_cons is not None: s_cons = cos_to_01(emb_pdf @ e_cons)\n",
    "    if e_lvl  is not None: s_lvl  = cos_to_01(emb_level @ e_lvl)\n",
    "    if e_lang is not None: s_lang = cos_to_01(emb_lang  @ e_lang)\n",
    "\n",
    "    # TF-IDF hybrid (topic + constraints)\n",
    "    s_look_tfidf = np.zeros(n, dtype=\"float32\")\n",
    "    s_cons_tfidf = np.zeros(n, dtype=\"float32\")\n",
    "    if q_look:\n",
    "        qv = tfidf_query_vector(q_look_expanded, vocab)\n",
    "        s_look_tfidf = (tfidf_mat @ qv.T).toarray().ravel().astype(\"float32\")\n",
    "        if s_look_tfidf.max() > 0: s_look_tfidf /= s_look_tfidf.max()\n",
    "    if q_cons:\n",
    "        qv2 = tfidf_query_vector(q_cons, vocab)\n",
    "        s_cons_tfidf = (tfidf_mat @ qv2.T).toarray().ravel().astype(\"float32\")\n",
    "        if s_cons_tfidf.max() > 0: s_cons_tfidf /= s_cons_tfidf.max()\n",
    "\n",
    "    final = (\n",
    "        W_EMB_LOOK  * s_look +\n",
    "        W_EMB_CONS  * s_cons +\n",
    "        W_EMB_LANG  * s_lang +\n",
    "        W_EMB_LEVEL * s_lvl  +\n",
    "        W_TFIDF_LOOK * s_look_tfidf +\n",
    "        W_TFIDF_CONS * s_cons_tfidf\n",
    "    )\n",
    "\n",
    "    out = df[[COL_NAME, COL_URL, COL_PDF, COL_LEVEL, COL_LANG]].copy()\n",
    "    out[\"looking_for_score\"] = s_look\n",
    "    out[\"constraint_score\"]  = s_cons\n",
    "    out[\"language_score\"]    = s_lang\n",
    "    out[\"job_level_score\"]   = s_lvl\n",
    "    out[\"final_score\"]       = final\n",
    "    out = out.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Coverage helpers\n",
    "def ensure_top_coverage(df_ranked: pd.DataFrame,\n",
    "                        skills_required: List[str],\n",
    "                        letters_required: List[str],\n",
    "                        top_m:int=GUARANTEE_TOP,\n",
    "                        also_ensure_in_topN: int=TOP_N) -> pd.DataFrame:\n",
    "    dfw = df_ranked.copy()\n",
    "\n",
    "    def contains_skill(text, skill):\n",
    "        return skill.lower() in text.lower()\n",
    "\n",
    "    LEX = {\n",
    "        \"A\": [\"aptitude\", \"reasoning\", \"numerical\", \"verbal\"],\n",
    "        \"P\": [\"personality\", \"work style\", \"culture\", \"behavior\"],\n",
    "        \"C\": [\"leadership\", \"communication\", \"collaboration\", \"problem solving\"],\n",
    "        \"K\": [\"knowledge\", \"skills\", \"python\", \"sql\", \"java\", \"c++\", \"domain\"],\n",
    "        \"S\": [\"simulation\", \"in-tray\", \"inbox\", \"case study\"],\n",
    "        \"E\": [\"presentation\", \"group exercise\", \"written task\"],\n",
    "        \"B\": [\"situational judgment\", \"past behavior\"],\n",
    "        \"D\": [\"development\", \"360\", \"coaching\"]\n",
    "    }\n",
    "    def contains_letter(text, letter):\n",
    "        t = text.lower()\n",
    "        return any(p in t for p in LEX.get(letter, []))\n",
    "\n",
    "    # ensure skill coverage\n",
    "    for skill in skills_required:\n",
    "        if not any(contains_skill(dfw.loc[i, COL_PDF], skill) for i in range(min(top_m, len(dfw)))):\n",
    "            for j in range(top_m, min(also_ensure_in_topN, len(dfw))):\n",
    "                if contains_skill(dfw.loc[j, COL_PDF], skill):\n",
    "                    row = dfw.iloc[[j]]\n",
    "                    dfw = pd.concat([dfw.iloc[:top_m-1], row, dfw.drop(dfw.index[j]).iloc[top_m-1:]]).reset_index(drop=True)\n",
    "                    break\n",
    "\n",
    "    # ensure letter/category coverage\n",
    "    for letter in letters_required:\n",
    "        if not any(contains_letter(dfw.loc[i, COL_PDF], letter) for i in range(min(top_m, len(dfw)))):\n",
    "            for j in range(top_m, min(also_ensure_in_topN, len(dfw))):\n",
    "                if contains_letter(dfw.loc[j, COL_PDF], letter):\n",
    "                    row = dfw.iloc[[j]]\n",
    "                    dfw = pd.concat([dfw.iloc[:top_m-1], row, dfw.drop(dfw.index[j]).iloc[top_m-1:]]).reset_index(drop=True)\n",
    "                    break\n",
    "\n",
    "    return dfw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef896d40",
   "metadata": {},
   "source": [
    "Time parser & package composer (multi-skill within budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0cbd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_minutes(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Heuristic: parse '45 minutes', '60 min', ranges '40-60 minutes'.\n",
    "    Returns median of found numbers; 0 if none (treat as unknown).\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    nums = []\n",
    "    for m in re.finditer(r\"(\\d+)\\s*-\\s*(\\d+)\\s*(?:mins?|minutes)\", t):\n",
    "        a,b = int(m.group(1)), int(m.group(2)); nums.extend([a,b])\n",
    "    for m in re.finditer(r\"(\\d+)\\s*(?:mins?|minutes)\", t):\n",
    "        nums.append(int(m.group(1)))\n",
    "    if not nums: return 0\n",
    "    return int(np.median(nums))\n",
    "\n",
    "def compose_package(df_ranked: pd.DataFrame,\n",
    "                    skills: List[str],\n",
    "                    time_budget: int) -> Tuple[List[dict], int]:\n",
    "    \"\"\"\n",
    "    Greedy set cover under time budget:\n",
    "    pick items that cover the most uncovered skills per minute, favoring higher-ranked ones.\n",
    "    \"\"\"\n",
    "    chosen, covered, total_time = [], set(), 0\n",
    "    items = []\n",
    "    for _, r in df_ranked.iterrows():\n",
    "        txt = r[COL_PDF]\n",
    "        minutes = extract_minutes(txt) or 30  # fallback default if unknown\n",
    "        item_skills = [s for s in skills if s.lower() in txt.lower()]\n",
    "        items.append((r, minutes, set(map(str.lower, item_skills))))\n",
    "\n",
    "    remaining = set(map(str.lower, skills))\n",
    "    while remaining:\n",
    "        best, best_gain = None, 0\n",
    "        for r, minutes, item_skills in items:\n",
    "            gain = len(item_skills & remaining)\n",
    "            if gain <= 0: \n",
    "                continue\n",
    "            if total_time + minutes > time_budget:\n",
    "                continue\n",
    "            # Utility: more coverage per minute, lightly reward better final_score\n",
    "            utility = (gain * (1.0 + float(r[\"final_score\"]))) / max(10, minutes)\n",
    "            if utility > best_gain:\n",
    "                best, best_gain = (r, minutes, item_skills), utility\n",
    "        if best is None:\n",
    "            break\n",
    "        r, minutes, item_skills = best\n",
    "        chosen.append({\"name\": r[COL_NAME], \"url\": r[COL_URL], \"minutes\": minutes, \"covers\": list(item_skills)})\n",
    "        total_time += minutes\n",
    "        remaining -= item_skills\n",
    "\n",
    "    return chosen, total_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87fb40",
   "metadata": {},
   "source": [
    "End-to-end recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b0a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_skills_from_looking_for(text: str) -> List[str]:\n",
    "    # Minimal keyword skill extractor; extend as needed\n",
    "    candidates = [\"python\",\"sql\",\"javascript\",\"java\",\"c++\",\"react\",\"excel\",\"leadership\",\"communication\"]\n",
    "    t = text.lower()\n",
    "    return [s for s in candidates if s in t]\n",
    "\n",
    "def recommend(query: dict):\n",
    "    # 1) Score\n",
    "    ranked = score_query(query)\n",
    "\n",
    "    # 2) Coverage in top-N\n",
    "    skills_req  = parse_skills_from_looking_for(query.get(\"looking_for\",\"\"))\n",
    "    letters_req = [x.strip() for x in query.get(\"need_to_assess\",\"\").split(\",\") if x.strip()]\n",
    "    ranked_cov  = ensure_top_coverage(ranked, skills_req, letters_req, top_m=GUARANTEE_TOP, also_ensure_in_topN=TOP_N)\n",
    "\n",
    "    # 3) Package if max time in constraints (e.g., \"max 60 minutes\")\n",
    "    time_budget = 0\n",
    "    cons = query.get(\"constraints\",\"\").lower()\n",
    "    m = re.search(r\"(?:max|maximum)\\s*(\\d{1,3})\\s*(?:mins?|minutes)\", cons)\n",
    "    if m:\n",
    "        time_budget = int(m.group(1))\n",
    "\n",
    "    package, total_time = [], 0\n",
    "    if time_budget > 0 and len(skills_req) >= 2:\n",
    "        package, total_time = compose_package(ranked_cov.head(50), skills_req, time_budget)\n",
    "\n",
    "    # 4) Prepare topN with a brief why\n",
    "    topN = ranked_cov.head(TOP_N).copy()\n",
    "    def why(r):\n",
    "        return (f\"topic={r['looking_for_score']:.2f} | cons={r['constraint_score']:.2f} | \"\n",
    "                f\"lang={r['language_score']:.2f} | level={r['job_level_score']:.2f}\")\n",
    "    topN[\"why\"] = topN.apply(why, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"topN\": topN[[COL_NAME, COL_URL, \"final_score\", \"why\"]],\n",
    "        \"skills_required\": skills_req,\n",
    "        \"letters_required\": letters_req,\n",
    "        \"package\": package,\n",
    "        \"package_total_minutes\": total_time,\n",
    "        \"time_budget\": time_budget\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0422776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Query_Restructured import get_assessment_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f5c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtions to recheck and make sure output from get_assessment_summmary and recommend is in correct format\n",
    "\n",
    "import json, re\n",
    "import pandas as pd\n",
    "\n",
    "def _robust_parse_summary(json_text):\n",
    "    \"\"\"Safely extract and parse the JSON block from LLM output.\"\"\"\n",
    "    if isinstance(json_text, dict):\n",
    "        d = json_text\n",
    "    else:\n",
    "        if not isinstance(json_text, str):\n",
    "            return {}\n",
    "        start, end = json_text.find(\"{\"), json_text.rfind(\"}\")\n",
    "        if start == -1 or end == -1 or end <= start:\n",
    "            return {}\n",
    "        try:\n",
    "            d = json.loads(json_text[start:end+1])\n",
    "        except Exception:\n",
    "            return {}\n",
    "    for k in [\"looking_for\",\"constraints\",\"job_level\",\"need_to_assess\",\"language\"]:\n",
    "        d.setdefault(k, \"\")\n",
    "        if not isinstance(d[k], str):\n",
    "            d[k] = str(d[k])\n",
    "    return d\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1334d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACK] 1/1: {\"ack\":\"received\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'looking_for': 'Assess candidates proficient in Python, SQL, and JavaScript for a technical role.',\n",
       " 'constraints': '',\n",
       " 'job_level': 'unknown',\n",
       " 'need_to_assess': 'K,P',\n",
       " 'language': 'unknown'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query = \"To assess candidates proficient in Python, SQL, and JavaScript for a technical role, ensuring they also demonstrate a good cultural fit with the company.\"\n",
    "prompt_new = get_assessment_summary(Query)\n",
    "prompt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e06f3bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'looking_for': 'Assess candidates proficient in Python, SQL, and JavaScript for a technical role.',\n",
       " 'constraints': '',\n",
       " 'job_level': 'unknown',\n",
       " 'need_to_assess': 'K,P',\n",
       " 'language': 'unknown'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_new = _robust_parse_summary(prompt_new)\n",
    "prompt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d4f6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_new = {\n",
    "  \"looking_for\": \"A Research Engineer with expertise in AI/ML, including Natural Language Processing, computer vision, and generative AI, proficient in Python and ML frameworks like TensorFlow and PyTorch, to develop, prototype, and deploy robust AI/ML models and influence product roadmaps. The assessment should screen candidates' technical knowledge and practical application skills.\",\n",
    "  \"constraints\": \"max assessment time in mins: 30\",\n",
    "  \"job_level\": \"mid\",\n",
    "  \"need_to_assess\": \"K,S,C,A\",\n",
    "  \"language\": \"English\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "279c7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f5bad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_url</th>\n",
       "      <th>final_score</th>\n",
       "      <th>why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Skills</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>1.056579</td>\n",
       "      <td>topic=0.80 | cons=0.73 | lang=0.91 | level=0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.953750</td>\n",
       "      <td>topic=0.75 | cons=0.66 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interpersonal Communications</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.905916</td>\n",
       "      <td>topic=0.68 | cons=0.64 | lang=0.91 | level=0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multitasking Ability</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.855121</td>\n",
       "      <td>topic=0.69 | cons=0.68 | lang=0.91 | level=0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.891213</td>\n",
       "      <td>topic=0.73 | cons=0.63 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job Control Language (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.884004</td>\n",
       "      <td>topic=0.72 | cons=0.67 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Visual Basic for Applications (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.880677</td>\n",
       "      <td>topic=0.68 | cons=0.63 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verify - Verbal Ability - Next Generation</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.872818</td>\n",
       "      <td>topic=0.70 | cons=0.69 | lang=0.86 | level=0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Siebel Development (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.866747</td>\n",
       "      <td>topic=0.70 | cons=0.61 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Global Skills Assessment</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.861741</td>\n",
       "      <td>topic=0.68 | cons=0.68 | lang=0.71 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Paint Technology (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.861666</td>\n",
       "      <td>topic=0.65 | cons=0.61 | lang=0.91 | level=0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mechatronics Engineering (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.861419</td>\n",
       "      <td>topic=0.68 | cons=0.61 | lang=0.91 | level=0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SonarQube (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.859013</td>\n",
       "      <td>topic=0.66 | cons=0.62 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R Programming (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.857247</td>\n",
       "      <td>topic=0.67 | cons=0.66 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Basic Computer Literacy (Windows 10) (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.854291</td>\n",
       "      <td>topic=0.68 | cons=0.60 | lang=0.91 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Software Business Analysis</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.854228</td>\n",
       "      <td>topic=0.69 | cons=0.62 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verify - Technical Checking - Next Generation</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.850095</td>\n",
       "      <td>topic=0.67 | cons=0.70 | lang=0.70 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Computer Science (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.850006</td>\n",
       "      <td>topic=0.66 | cons=0.62 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Automation Anywhere RPA Development (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.848830</td>\n",
       "      <td>topic=0.72 | cons=0.63 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UiPath RPA Development (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.848509</td>\n",
       "      <td>topic=0.72 | cons=0.65 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Android Development (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.847449</td>\n",
       "      <td>topic=0.66 | cons=0.63 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SHL Verify Interactive – Numerical Reasoning</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.847072</td>\n",
       "      <td>topic=0.69 | cons=0.69 | lang=0.70 | level=0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Verify - Inductive Reasoning (2014)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.844102</td>\n",
       "      <td>topic=0.72 | cons=0.64 | lang=0.68 | level=0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Microsoft Excel 365 - Essentials (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.841593</td>\n",
       "      <td>topic=0.66 | cons=0.68 | lang=0.91 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dojo (New)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.840742</td>\n",
       "      <td>topic=0.67 | cons=0.62 | lang=0.91 | level=0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  assessment_name  \\\n",
       "0                                       AI Skills   \n",
       "1                              Data Science (New)   \n",
       "2                    Interpersonal Communications   \n",
       "3                            Multitasking Ability   \n",
       "4                                    Python (New)   \n",
       "5                      Job Control Language (New)   \n",
       "6             Visual Basic for Applications (New)   \n",
       "7       Verify - Verbal Ability - Next Generation   \n",
       "8                        Siebel Development (New)   \n",
       "9                        Global Skills Assessment   \n",
       "10                         Paint Technology (New)   \n",
       "11                 Mechatronics Engineering (New)   \n",
       "12                                SonarQube (New)   \n",
       "13                            R Programming (New)   \n",
       "14     Basic Computer Literacy (Windows 10) (New)   \n",
       "15                     Software Business Analysis   \n",
       "16  Verify - Technical Checking - Next Generation   \n",
       "17                         Computer Science (New)   \n",
       "18      Automation Anywhere RPA Development (New)   \n",
       "19                   UiPath RPA Development (New)   \n",
       "20                      Android Development (New)   \n",
       "21   SHL Verify Interactive – Numerical Reasoning   \n",
       "22            Verify - Inductive Reasoning (2014)   \n",
       "23         Microsoft Excel 365 - Essentials (New)   \n",
       "24                                     Dojo (New)   \n",
       "\n",
       "                                       assessment_url  final_score  \\\n",
       "0   https://www.shl.com/products/product-catalog/v...     1.056579   \n",
       "1   https://www.shl.com/products/product-catalog/v...     0.953750   \n",
       "2   https://www.shl.com/products/product-catalog/v...     0.905916   \n",
       "3   https://www.shl.com/products/product-catalog/v...     0.855121   \n",
       "4   https://www.shl.com/products/product-catalog/v...     0.891213   \n",
       "5   https://www.shl.com/products/product-catalog/v...     0.884004   \n",
       "6   https://www.shl.com/products/product-catalog/v...     0.880677   \n",
       "7   https://www.shl.com/products/product-catalog/v...     0.872818   \n",
       "8   https://www.shl.com/products/product-catalog/v...     0.866747   \n",
       "9   https://www.shl.com/products/product-catalog/v...     0.861741   \n",
       "10  https://www.shl.com/products/product-catalog/v...     0.861666   \n",
       "11  https://www.shl.com/products/product-catalog/v...     0.861419   \n",
       "12  https://www.shl.com/products/product-catalog/v...     0.859013   \n",
       "13  https://www.shl.com/products/product-catalog/v...     0.857247   \n",
       "14  https://www.shl.com/products/product-catalog/v...     0.854291   \n",
       "15  https://www.shl.com/products/product-catalog/v...     0.854228   \n",
       "16  https://www.shl.com/products/product-catalog/v...     0.850095   \n",
       "17  https://www.shl.com/products/product-catalog/v...     0.850006   \n",
       "18  https://www.shl.com/products/product-catalog/v...     0.848830   \n",
       "19  https://www.shl.com/products/product-catalog/v...     0.848509   \n",
       "20  https://www.shl.com/products/product-catalog/v...     0.847449   \n",
       "21  https://www.shl.com/products/product-catalog/v...     0.847072   \n",
       "22  https://www.shl.com/products/product-catalog/v...     0.844102   \n",
       "23  https://www.shl.com/products/product-catalog/v...     0.841593   \n",
       "24  https://www.shl.com/products/product-catalog/v...     0.840742   \n",
       "\n",
       "                                                why  \n",
       "0   topic=0.80 | cons=0.73 | lang=0.91 | level=0.52  \n",
       "1   topic=0.75 | cons=0.66 | lang=0.91 | level=0.61  \n",
       "2   topic=0.68 | cons=0.64 | lang=0.91 | level=0.62  \n",
       "3   topic=0.69 | cons=0.68 | lang=0.91 | level=0.63  \n",
       "4   topic=0.73 | cons=0.63 | lang=0.91 | level=0.61  \n",
       "5   topic=0.72 | cons=0.67 | lang=0.91 | level=0.61  \n",
       "6   topic=0.68 | cons=0.63 | lang=0.91 | level=0.61  \n",
       "7   topic=0.70 | cons=0.69 | lang=0.86 | level=0.60  \n",
       "8   topic=0.70 | cons=0.61 | lang=0.91 | level=0.61  \n",
       "9   topic=0.68 | cons=0.68 | lang=0.71 | level=0.64  \n",
       "10  topic=0.65 | cons=0.61 | lang=0.91 | level=0.62  \n",
       "11  topic=0.68 | cons=0.61 | lang=0.91 | level=0.60  \n",
       "12  topic=0.66 | cons=0.62 | lang=0.91 | level=0.61  \n",
       "13  topic=0.67 | cons=0.66 | lang=0.91 | level=0.61  \n",
       "14  topic=0.68 | cons=0.60 | lang=0.91 | level=0.65  \n",
       "15  topic=0.69 | cons=0.62 | lang=0.91 | level=0.61  \n",
       "16  topic=0.67 | cons=0.70 | lang=0.70 | level=0.65  \n",
       "17  topic=0.66 | cons=0.62 | lang=0.91 | level=0.61  \n",
       "18  topic=0.72 | cons=0.63 | lang=0.91 | level=0.61  \n",
       "19  topic=0.72 | cons=0.65 | lang=0.91 | level=0.61  \n",
       "20  topic=0.66 | cons=0.63 | lang=0.91 | level=0.61  \n",
       "21  topic=0.69 | cons=0.69 | lang=0.70 | level=0.59  \n",
       "22  topic=0.72 | cons=0.64 | lang=0.68 | level=0.59  \n",
       "23  topic=0.66 | cons=0.68 | lang=0.91 | level=0.65  \n",
       "24  topic=0.67 | cons=0.62 | lang=0.91 | level=0.61  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res1 = recommend(prompt_new)\n",
    "display(res1[\"topN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae29becf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4ef13",
   "metadata": {},
   "source": [
    "### Testing Recall@10 for single query from Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afafd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labeled urls from the dataset\n",
    "check = {\n",
    "    \"Query\": \"I want to hire new graduates for a sales role in my company, the budget is for about an hour for each test. Give me some options\",\n",
    "    \"assessment_url\": [\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/entry-level-sales-7-1/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/entry-level-sales-sift-out-7-1/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/entry-level-sales-solution/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/sales-representative-solution/\",\n",
    "      \"https://www.shl.com/products/product-catalog/view/business-communication-adaptive/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/technical-sales-associate-solution/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/svar-spoken-english-indian-accent-new/\",\n",
    "      \"https://www.shl.com/products/product-catalog/view/interpersonal-communications/\",\n",
    "      \"https://www.shl.com/solutions/products/product-catalog/view/english-comprehension-new/\"\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0009b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def _normalize_url(u: str) -> str:\n",
    "    if not isinstance(u, str): return \"\"\n",
    "    s = u.strip().lower()\n",
    "    s = s.replace(\"https://\",\"\").replace(\"http://\",\"\")\n",
    "    if s.startswith(\"www.\"): s = s[4:]\n",
    "    s = re.sub(r\"[#?].*$\", \"\", s)  # drop query/fragment\n",
    "    if s.endswith(\"/\"): s = s[:-1]\n",
    "    return s\n",
    "\n",
    "def _slug(u: str) -> str:\n",
    "    u = _normalize_url(u)\n",
    "    m = re.search(r\"/view/([^/?#]+)\", u)\n",
    "    if m: return m.group(1)\n",
    "    parts = [p for p in u.split(\"/\") if p]\n",
    "    return parts[-1] if parts else u\n",
    "\n",
    "def _robust_parse_summary(json_text: str) -> dict:\n",
    "    if not isinstance(json_text, str):\n",
    "        return json_text if isinstance(json_text, dict) else {}\n",
    "    start, end = json_text.find(\"{\"), json_text.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end <= start:\n",
    "        return {}\n",
    "    try:\n",
    "        data = json.loads(json_text[start:end+1])\n",
    "    except Exception:\n",
    "        return {}\n",
    "    # coerce expected keys\n",
    "    for k in [\"looking_for\",\"constraints\",\"job_level\",\"need_to_assess\",\"language\"]:\n",
    "        data.setdefault(k, \"\")\n",
    "        if not isinstance(data[k], str):\n",
    "            data[k] = str(data[k])\n",
    "    return data\n",
    "\n",
    "def _extract_pred_urls_from_topN(topN, k: int = 10) -> list[str]:\n",
    "    urls = []\n",
    "    if isinstance(topN, pd.DataFrame):\n",
    "        # try common URL columns\n",
    "        for col in [\"assessment_url\",\"url\",\"URL\",\"link\",\"href\"]:\n",
    "            if col in topN.columns:\n",
    "                urls = topN[col].astype(str).head(k).tolist()\n",
    "                break\n",
    "    elif isinstance(topN, (list, tuple)) and topN:\n",
    "        if isinstance(topN[0], dict):\n",
    "            for col in [\"assessment_url\",\"url\",\"URL\",\"link\",\"href\"]:\n",
    "                if col in topN[0]:\n",
    "                    urls = [str(d.get(col,\"\")) for d in topN[:k]]\n",
    "                    break\n",
    "        else:\n",
    "            urls = [str(x) for x in topN[:k]]\n",
    "    return urls\n",
    "\n",
    "def recall_at_k_single(check: dict, K: int = 10, verbose: bool = True) -> float:\n",
    "    \"\"\"\n",
    "    check = {\n",
    "        \"Query\": \"...\",\n",
    "        \"assessment_url\": [list of ground-truth URLs]\n",
    "    }\n",
    "    Returns Recall@K (float). Prints details if verbose=True.\n",
    "    \"\"\"\n",
    "    query_text = check.get(\"Query\",\"\")\n",
    "    gt_urls = [u for u in check.get(\"assessment_url\", []) if u]\n",
    "    gt_slugs = {_slug(u) for u in gt_urls}\n",
    "\n",
    "    # 1) Summarize query with your LLM\n",
    "    prompt_out = get_assessment_summary(query_text)\n",
    "\n",
    "    # 2) Call your recommender.\n",
    "    #    Your current usage is recommend(prompt_string), but if it expects a dict\n",
    "    #    we’ll parse and try recommend(parsed_dict) as a fallback.\n",
    "    try:\n",
    "        rec = recommend(prompt_out)\n",
    "    except Exception:\n",
    "        parsed = _robust_parse_summary(prompt_out)\n",
    "        rec = recommend(parsed)\n",
    "\n",
    "    topN = rec.get(\"topN\", None) if isinstance(rec, dict) else rec\n",
    "    pred_urls = _extract_pred_urls_from_topN(topN, k=K)\n",
    "    pred_slugs = [_slug(u) for u in pred_urls if u]\n",
    "\n",
    "    # 3) Compute recall\n",
    "    hits = len(set(pred_slugs) & gt_slugs)\n",
    "    denom = max(len(gt_slugs), 1)\n",
    "    recall_k = hits / denom\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=\"*80)\n",
    "        print(\"Query:\")\n",
    "        print(query_text)\n",
    "        print(\"\\nParsed JSON from summarizer:\")\n",
    "        print(_robust_parse_summary(prompt_out))\n",
    "        if isinstance(topN, pd.DataFrame):\n",
    "            show_cols = [c for c in [\"assessment_name\",\"assessment_url\",\"final_score\",\"why\"] if c in topN.columns]\n",
    "            print(\"\\nTop-K table:\")\n",
    "            display(topN[show_cols].head(K))\n",
    "        print(\"\\nGround-truth slugs:\")\n",
    "        print(sorted(gt_slugs))\n",
    "        print(\"\\nPredicted slugs:\")\n",
    "        print(pred_slugs)\n",
    "        print(f\"\\nHits@{K}: {hits} / {len(gt_slugs)}  →  Recall@{K}: {recall_k:.4f}\")\n",
    "\n",
    "    return recall_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e81c0920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "================================================================================\n",
      "Query:\n",
      "I want to hire new graduates for a sales role in my company, the budget is for about an hour for each test. Give me some options\n",
      "\n",
      "Parsed JSON from summarizer:\n",
      "{'looking_for': 'A summary for new graduates applying for a sales role, focusing on assessing their communication, persuasion, and problem-solving skills.', 'constraints': 'average assessment time: 60 mins', 'job_level': 'junior', 'need_to_assess': 'C,B,P,S,A', 'language': 'unknown'}\n",
      "\n",
      "Top-K table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_url</th>\n",
       "      <th>final_score</th>\n",
       "      <th>why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interpersonal Communications</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.938613</td>\n",
       "      <td>topic=0.74 | cons=0.65 | lang=0.60 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Communication (adaptive)</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.880010</td>\n",
       "      <td>topic=0.71 | cons=0.64 | lang=0.60 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multitasking Ability</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.852732</td>\n",
       "      <td>topic=0.68 | cons=0.67 | lang=0.60 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retail Sales and Service Simulation</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.817455</td>\n",
       "      <td>topic=0.78 | cons=0.58 | lang=0.60 | level=0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sales Interview Guide</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.833823</td>\n",
       "      <td>topic=0.81 | cons=0.54 | lang=0.65 | level=0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SHL Verify Interactive – Numerical Reasoning</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.826681</td>\n",
       "      <td>topic=0.68 | cons=0.66 | lang=0.55 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPQ MQ Sales Report</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.821911</td>\n",
       "      <td>topic=0.81 | cons=0.54 | lang=0.55 | level=0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Graduate Scenarios</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.814403</td>\n",
       "      <td>topic=0.75 | cons=0.66 | lang=0.65 | level=0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verify - General Ability Screen</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.798859</td>\n",
       "      <td>topic=0.72 | cons=0.67 | lang=0.54 | level=0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Occupational Personality Questionnaire OPQ32r</td>\n",
       "      <td>https://www.shl.com/products/product-catalog/v...</td>\n",
       "      <td>0.796134</td>\n",
       "      <td>topic=0.71 | cons=0.65 | lang=0.55 | level=0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 assessment_name  \\\n",
       "0                   Interpersonal Communications   \n",
       "1              Business Communication (adaptive)   \n",
       "2                           Multitasking Ability   \n",
       "3            Retail Sales and Service Simulation   \n",
       "4                          Sales Interview Guide   \n",
       "5   SHL Verify Interactive – Numerical Reasoning   \n",
       "6                            OPQ MQ Sales Report   \n",
       "7                             Graduate Scenarios   \n",
       "8                Verify - General Ability Screen   \n",
       "9  Occupational Personality Questionnaire OPQ32r   \n",
       "\n",
       "                                      assessment_url  final_score  \\\n",
       "0  https://www.shl.com/products/product-catalog/v...     0.938613   \n",
       "1  https://www.shl.com/products/product-catalog/v...     0.880010   \n",
       "2  https://www.shl.com/products/product-catalog/v...     0.852732   \n",
       "3  https://www.shl.com/products/product-catalog/v...     0.817455   \n",
       "4  https://www.shl.com/products/product-catalog/v...     0.833823   \n",
       "5  https://www.shl.com/products/product-catalog/v...     0.826681   \n",
       "6  https://www.shl.com/products/product-catalog/v...     0.821911   \n",
       "7  https://www.shl.com/products/product-catalog/v...     0.814403   \n",
       "8  https://www.shl.com/products/product-catalog/v...     0.798859   \n",
       "9  https://www.shl.com/products/product-catalog/v...     0.796134   \n",
       "\n",
       "                                               why  \n",
       "0  topic=0.74 | cons=0.65 | lang=0.60 | level=0.64  \n",
       "1  topic=0.71 | cons=0.64 | lang=0.60 | level=0.64  \n",
       "2  topic=0.68 | cons=0.67 | lang=0.60 | level=0.65  \n",
       "3  topic=0.78 | cons=0.58 | lang=0.60 | level=0.68  \n",
       "4  topic=0.81 | cons=0.54 | lang=0.65 | level=0.65  \n",
       "5  topic=0.68 | cons=0.66 | lang=0.55 | level=0.64  \n",
       "6  topic=0.81 | cons=0.54 | lang=0.55 | level=0.63  \n",
       "7  topic=0.75 | cons=0.66 | lang=0.65 | level=0.64  \n",
       "8  topic=0.72 | cons=0.67 | lang=0.54 | level=0.68  \n",
       "9  topic=0.71 | cons=0.65 | lang=0.55 | level=0.64  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ground-truth slugs:\n",
      "['business-communication-adaptive', 'english-comprehension-new', 'entry-level-sales-7-1', 'entry-level-sales-sift-out-7-1', 'entry-level-sales-solution', 'interpersonal-communications', 'sales-representative-solution', 'svar-spoken-english-indian-accent-new', 'technical-sales-associate-solution']\n",
      "\n",
      "Predicted slugs:\n",
      "['interpersonal-communications', 'business-communication-adaptive', 'multitasking-ability', 'retail-sales-and-service-simulation', 'sales-interview-guide', 'shl-verify-interactive-numerical-reasoning', 'opq-mq-sales-report', 'graduate-scenarios', 'verify-general-ability-screen', 'occupational-personality-questionnaire-opq32r']\n",
      "\n",
      "Hits@10: 2 / 9  →  Recall@10: 0.2222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k_single(check, K=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bdb1c9",
   "metadata": {},
   "source": [
    "### Recall@10 Evaluation from the whole train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b8b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "# Delete prediction cache files\n",
    "for f in glob.glob(\"pred_cache.json*\"):\n",
    "    try:\n",
    "        os.remove(f)\n",
    "        print(f\"Deleted cache file: {f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not delete {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61594603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "[ACK] 1/1: {\"ack\":\"received\"}\n",
      "{\n",
      "  \"Based on the JD below recommend me assessment for the Consultant position in my organizations. The assessment should not be more than 90 mins\\nb Description\\n\\n Job Purpose \\n\\nResponsibilities\\n\\nThe Consultant role supports the broader professional services organization by leading the delivery of impactful client solutions and advising on client programs. Consultants are expected to deliver solutions, services, and insights that are driven by industry best practices and that positively impact client business objectives and partnerships. Individuals in this role provide I/O technical guidance to internal and external stakeholders, and drive continuous improvement related to project delivery.  Primary Duties and Responsibilities  Primary job duties and responsibilities include but may not be limited to:\\n\\n Planning, executing, and documenting projects related to clients’ talent assessment and development needs (e.g., job analysis, validation, leadership assessment, succession planning, program implementation, adverse impact analyses, best practices). \\n Leading projects; ensuring overall quality for all client deliverables and guiding other to do the same. \\n Serving as an expert resource to clients and internal stakeholders about issues related to talent assessment, selection, and development. \\n Linking human capital insights to business outcomes and demonstrating ROI. \\n Collaborating with members of the Sales team to manage existing programs and identify new business opportunities. \\n Maintaining up-to-date knowledge of the field including empirical research, industry trends, and competitors. \\n Providing talent analytics and data insights to technical and non-technical stakeholders. \\n Contributing to the ongoing definition and development of SHL’s offerings and methodologies. \\n Presenting to and interacting with senior client stakeholders. \\n Providing thought leadership; working with delivery and commercial teams to drive improvements in the scoping and execution of projects/deliverables. \\n\\n Key Competencies: \\n\\n Decision Making \\n Collaboration \\n Building Relationships \\n Creativity and Innovation \\n Planning and Organizing \\n Delivering Results \\n Adaptability \\n\\n Qualifications include: \\n\\n A graduate degree in Industrial/Organizational psychology or a related discipline \\n 2+ years of relevant work experience in applied talent assessment, talent management, or employee selection, including program design and implementation \\n Client-facing delivery experience with design and implementation of talent assessment programs (including job analysis, criterion validation, content validation, and interviews) \\n Selection system development and / or evaluation \\n Proficient in at least one statistical program (e.g., SPSS, R) \\n Strong communication skills and presenting technical results to non-technical stakeholders \\n\\n#IO #IndustrialPsychology #psychtalent #talentmanagement #talentassessment #psychometrics #consultant\\n\\nAbout Us\\n\\nWe unlock the possibilities of businesses through the power of people, science, and technology.\\n\\nWe started this industry of people insight more than 40 years ago and continue to lead the market with powerhouse product launches, ground-breaking science, and business transformation.\\n\\nWhen you inspire and transform people’s lives, you will experience the greatest business outcomes possible. SHL’s products insights, experiences, and services can help achieve growth at scale.\\n\\nMore at shl.com.\\n\\nWhat SHL Can Offer You\\n\\n An inclusive culture. \\n A fun and flexible workplace where you’ll be inspired to do your best work. \\n Employee benefits package that takes care of you and your family. \\n Support, coaching, and on-the-job development to achieve career success. \\n The ability to transform workplaces around the world for others. \\n\\nSHL is an equal opportunity employer.\": 0.2,\n",
      "  \"Content Writer required, expert in English and SEO.\": 0.6,\n",
      "  \"Find me 1 hour long assesment for the below job at SHL\\nJob Description\\n\\n Join a community that is shaping the future of work! SHL, People Science. People Answers. \\n\\nAre you a seasoned QA Engineer with a flair for innovation? Are you ready to shape the future of talent assessment and empower organizations to unlock their full potential? If so, we want you to be a part of the SHL Team! As a QA Engineer, you will be involved in creating and implementing software solutions that contribute to the development of our ground-breaking products.\\n\\nAn excellent benefit package is offered in a culture where career development, with ongoing manager guidance, collaboration, flexibility, diversity, and inclusivity are all intrinsic to our culture.  There is a huge investment in SHL currently so there’s no better time to become a part of something transformational.\\n\\nWhat You Will Be Doing\\n\\n Getting involved in engineering quality assurance and providing inputs when required. \\n Create and develop test plans for various forms of testing. \\n Conducts and/or participates in formal and informal test case reviews. \\n Develop and initiate functional tests and regression tests. \\n Rolling out improvements for testing and quality processes. \\n\\nEssential\\n\\n What we are looking for from you: \\n\\n Development experience – Java or JavaScript, CSS, HTML (Automation) \\n Selenium WebDriver and page object design pattern (Automation) \\n SQL server knowledge \\n Test case management experience. \\n Manual Testing \\n\\nDesirable\\n\\n Knowledge the basic concepts of testing \\n Strong solution-finding experience \\n Strong verbal and written communicator. \\n\\nGet In Touch\\n\\nFind out how this one-off opportunity can help you achieve your career goals by making an application to our knowledgeable and friendly Talent Acquisition team. Choose a new path with SHL.\\n\\n #CareersAtSHL #SHLHiringTalent \\n\\n#TechnologyJobs #QualityAssuranceJobs\\n\\n#CareerOpportunities #JobOpportunities \\n\\nAbout Us\\n\\nWe unlock the possibilities of businesses through the power of people, science and technology.\\nWe started this industry of people insight more than 40 years ago and continue to lead the market with powerhouse product launches, ground-breaking science and business transformation.\\nWhen you inspire and transform people’s lives, you will experience the greatest business outcomes possible. SHL’s products insights, experiences, and services can help achieve growth at scale.\\n\\nWhat SHL Can Offer You\\n\\nDiversity, equity, inclusion and accessibility are key threads in the fabric of SHL’s business and culture (find out more about DEI and accessibility at SHL )\\nEmployee benefits package that takes care of you and your family.\\nSupport, coaching, and on-the-job development to achieve career success\\nA fun and flexible workplace where you’ll be inspired to do your best work (find out more LifeAtSHL )\\nThe ability to transform workplaces around the world for others.\\n\\nSHL is an equal opportunity employer. We support and encourage applications from a diverse range of candidates. We can, and do make adjustments to make sure our recruitment process is as inclusive as possible.\\n\\nSHL is an equal opportunity employer.\": 0.6667,\n",
      "  \"I am hiring for Java developers who can also collaborate effectively with my business teams. Looking for an assessment(s) that can be completed in 40 minutes.\": 0.6,\n",
      "  \"I am looking for a COO for my company in China and I want to see if they are culturally a right fit for our company. Suggest me an assessment that they can complete in about an hour\": 0.3333,\n",
      "  \"I want to hire a Senior Data Analyst with 5 years of experience and expertise in SQL, Excel and Python. The assessment can be 1-2 hour long\": 0.5,\n",
      "  \"I want to hire new graduates for a sales role in my company, the budget is for about an hour for each test. Give me some options\": 0.2222,\n",
      "  \"ICICI Bank Assistant Admin, Experience required 0-2 years, test should be 30-40 mins long\": 0.0,\n",
      "  \"KEY RESPONSIBITILES:\\n\\nManage the sound-scape of the station through appropriate creative and marketing interventions to Increase or Maintain the listenership\\nActs as an interface between Programming & sales team, thereby supporting the sales team by providing creative inputs in order to increase the overall ad spends by clients\\nBuild brand Mirchi by ideating fresh programming initiatives on air campaigns, programming led on-ground events & new properties to ensure brand differentiation & thus increase brand recall at station level\\nInvest time in local RJs to grow & develop them as local celebrities\\nThrough strong networking, must focus on identifying the best of local talent and ensure to bring the creative minds from the market on board with Mirchi\\nBuild radio as a category for both listeners & advertisers\\nPeople Management\\nIdentifying the right talent and investing time in developing them by frequent feedback on their performance\\nMonitor, Coach and mentor team members on a regular basis\\nDevelopment of Jocks as per guidelines\\nMust have an eye to spot the local talent to fill up vacancies locally\\n\\n\\n\\n\\nTECHNICAL SKILLS & QUALIFICATION REQUIRED:\\n\\nGraduation / Post Graduation (Any specialisation) with 8 -12 years of relevant experience\\nExperience in digital content conceptualisation\\nStrong branding focus\\nMust be well-read in variety of areas and must keep up with the latest events in the city / cluster / country\\nMust know to read, write & speak English \\n\\n\\nPERSONAL ATTRIBUTES:\\n\\nExcellent communication skills\\nGood interpersonal skills\\nPeople management\\n\\n\\nSuggest me some tests for the above jd. The duration should be at most 90 mins\": 0.4,\n",
      "  \"We're looking for a Marketing Manager who can drive Recro’s brand positioning, community growth, and overall marketing strategy to fuel business growth. The ideal candidate is a strategic thinker, an execution-focused leader, and an expert in building high-performing marketing teams.\\n\\n\\n\\nAbout Recro \\n\\n\\nRecro is a developer-focused platform that was founded to match individual expertise with the right opportunities seamlessly. We empower talented developers by providing them with relevant experience at fast-growing startups based on technical competencies and aspirations. These opportunities have a significant impact on their career success and help them become their best self.\\n\\n\\nAbout The Role\\n\\nDevelop and execute Recro’s marketing strategy to enhance community engagement, brand positioning, and industry presence.\\nLead the marketing team and oversee all functions, with a strong focus on community building, events, brand positioning, social media engagement, and market intelligence.\\nDrive demand generation by leveraging community-driven initiatives, influencer partnerships, and strategic event participation.\\nOrganize and represent Recro at industry conferences, networking events, and developer meetups to strengthen brand positioning.\\nBuild and nurture relationships with industry influencers, developer communities, and partners to create brand advocates.\\nOwn the marketing funnel, ensuring continuous tracking, analysis, and optimization of community engagement and event performance.\\nCollaborate with sales, business development, and leadership teams to align marketing strategies with business objectives and market trends.\\nManage marketing budgets, prioritizing event sponsorships, partnerships, and community-driven growth initiatives.\\nDevelop compelling content strategies to drive community interaction and thought leadership.\\nStay ahead of industry trends, competitor movements, and emerging social and market intelligence to maintain a competitive edge\\n\\n\\nRequirements\\n\\n5+ years of experience in B2B marketing with a strong focus on community building, events, and brand positioning.\\nHas a deep understanding how demand generation works from traditional and new age channels\\nProven track record of executing large-scale events and community-driven initiatives.\\nExperience in developing partnerships with industry influencers and thought leaders.\\nStrong understanding of social media dynamics and community engagement strategies.\\nAbility to leverage market intelligence and competitor insights to refine marketing strategies.\\nExceptional storytelling and brand communication skills.\\nHands-on experience with event management, sponsorships, and partnership collaborations.\\nExperience in building a thriving developer or tech community is a plus.\\nOpen for flexible work timings as per target geographies.\\n\\nI have no bar on duration.\": 0.2,\n",
      "  \"Mean_Recall\": 0.3722\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re, json, time\n",
    "import pandas as pd\n",
    "\n",
    "# ------- CONFIG -------\n",
    "EXCEL_PATH = r\"C:\\Users\\vinee\\Downloads\\Gen_AI Dataset.xlsx\"  # <-- your dataset path\n",
    "QUERY_COL   = \"Query\"\n",
    "URL_COL     = \"Assessment_url\"\n",
    "K           = 10\n",
    "SLEEP_SEC   = 20   # delay between each query\n",
    "\n",
    "# ------- Helpers -------\n",
    "def _normalize_url(u: str) -> str:\n",
    "    if not isinstance(u, str): return \"\"\n",
    "    s = u.strip().lower().replace(\"https://\", \"\").replace(\"http://\", \"\")\n",
    "    if s.startswith(\"www.\"): s = s[4:]\n",
    "    s = re.sub(r\"[#?].*$\", \"\", s)\n",
    "    if s.endswith(\"/\"): s = s[:-1]\n",
    "    return s\n",
    "\n",
    "def _slug(u: str) -> str:\n",
    "    u = _normalize_url(u)\n",
    "    m = re.search(r\"/view/([^/?#]+)\", u)\n",
    "    if m: return m.group(1)\n",
    "    parts = [p for p in u.split(\"/\") if p]\n",
    "    return parts[-1] if parts else u\n",
    "\n",
    "def _robust_parse_summary(json_text: str) -> dict:\n",
    "    \"\"\"Extract first {...} object and coerce expected keys to strings. If already dict, pass through.\"\"\"\n",
    "    if isinstance(json_text, dict):\n",
    "        d = json_text\n",
    "    else:\n",
    "        if not isinstance(json_text, str):\n",
    "            return {}\n",
    "        start, end = json_text.find(\"{\"), json_text.rfind(\"}\")\n",
    "        if start == -1 or end == -1 or end <= start:\n",
    "            return {}\n",
    "        try:\n",
    "            d = json.loads(json_text[start:end+1])\n",
    "        except Exception:\n",
    "            return {}\n",
    "    for k in [\"looking_for\",\"constraints\",\"job_level\",\"need_to_assess\",\"language\"]:\n",
    "        d.setdefault(k, \"\")\n",
    "        if not isinstance(d[k], str): d[k] = str(d[k])\n",
    "    return d\n",
    "\n",
    "def _extract_pred_urls_from_topN(topN, k: int = 10) -> list[str]:\n",
    "    urls = []\n",
    "    if isinstance(topN, pd.DataFrame):\n",
    "        for col in [\"assessment_url\",\"url\",\"URL\",\"link\",\"href\"]:\n",
    "            if col in topN.columns:\n",
    "                urls = topN[col].astype(str).head(k).tolist()\n",
    "                break\n",
    "    elif isinstance(topN, (list, tuple)) and topN:\n",
    "        if isinstance(topN[0], dict):\n",
    "            for col in [\"assessment_url\",\"url\",\"URL\",\"link\",\"href\"]:\n",
    "                if col in topN[0]:\n",
    "                    urls = [str(d.get(col,\"\")) for d in topN[:k]]\n",
    "                    break\n",
    "        else:\n",
    "            urls = [str(x) for x in topN[:k]]\n",
    "    return urls\n",
    "\n",
    "def recall_at_k(true_slugs: set, pred_slugs: list, k: int) -> float:\n",
    "    if not true_slugs: return 0.0\n",
    "    return len(set(pred_slugs[:k]) & true_slugs) / len(true_slugs)\n",
    "\n",
    "# ------- Load dataset -------\n",
    "labels_df = pd.read_excel(EXCEL_PATH).fillna(\"\")\n",
    "if QUERY_COL not in labels_df.columns or URL_COL not in labels_df.columns:\n",
    "    raise ValueError(f\"Excel must have columns '{QUERY_COL}' and '{URL_COL}'\")\n",
    "\n",
    "labels_df[\"slug\"] = labels_df[URL_COL].astype(str).map(_slug)\n",
    "grouped = (\n",
    "    labels_df.groupby(QUERY_COL)[\"slug\"]\n",
    "    .apply(lambda s: set(u for u in s if u))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"slug\":\"relevant_slugs\"})\n",
    ")\n",
    "\n",
    "# ------- Evaluate silently -------\n",
    "recall_results = {}\n",
    "\n",
    "for i, row in grouped.iterrows():\n",
    "    q_text = row[QUERY_COL]\n",
    "    true_slugs = row[\"relevant_slugs\"]\n",
    "\n",
    "    prompt_out = get_assessment_summary(q_text)\n",
    "    q_obj = _robust_parse_summary(prompt_out)\n",
    "\n",
    "    try:\n",
    "        rec = recommend(prompt_out)\n",
    "    except Exception:\n",
    "        rec = recommend(q_obj)\n",
    "\n",
    "    topN = rec.get(\"topN\", None) if isinstance(rec, dict) else rec\n",
    "    pred_urls = _extract_pred_urls_from_topN(topN, k=K)\n",
    "    pred_slugs = [_slug(u) for u in pred_urls if u]\n",
    "\n",
    "    r_k = recall_at_k(true_slugs, pred_slugs, K)\n",
    "    recall_results[q_text] = round(r_k, 4)\n",
    "\n",
    "    # wait 20 seconds between queries\n",
    "    if i < len(grouped) - 1:\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "# ------- Compute mean recall -------\n",
    "mean_recall = round(sum(recall_results.values()) / len(recall_results), 4) if recall_results else 0.0\n",
    "recall_results[\"Mean_Recall\"] = mean_recall\n",
    "\n",
    "# ------- Final JSON-style output -------\n",
    "recall_results_json = json.dumps(recall_results, ensure_ascii=False, indent=2)\n",
    "print(recall_results_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682438e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shl_env (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
